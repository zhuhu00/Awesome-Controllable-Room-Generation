[![Awesome Logo](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)


# Overview

This repository collects studies on 3D controllable room level scene generation, along with the downstream applications, and will be continuously updated.

If you have suggestions for new resources, improvements to methodologies, or corrections for broken links, please don't hesitate to open an [issue](https://github.com/zhuhu00/Awesome-Controllable-Room-Generation/issues) or submit a [pull request](https://github.com/zhuhu00/Awesome-Controllable-Room-Generation/pulls). Contributions of all kinds are welcome and greatly appreciated.

To be updated. 


### Table of Contents

- [Methods: A Hierarchical Taxonomy](#methods-a-hierarchical-taxonomy)
  - [Procedural Generation](#procedural-generation)
    - [Rule-based Generation](#rule-based-generation)
    - [Optimization-based Generation](#optimization-based-generation)
    - [LLM-based Generation](#llm-based-generation)
  - [Neural-3D Generation](#neural-3d-generation)
    - [Scene Parameters](#scene-parameters)
    - [Scene Graph](#scene-graph)
    - [Semantic Layout](#semantic-layout)
    - [Implicit Layout](#implicit-layout)
  - [Image-based Generation](#image-based-generation)
    - [Holistic Generation](#holistic-generation)
    - [Iterative Generation](#iterative-generation)
  - [Video-based Generation](#video-based-generation)
    - [Two-stage Generation](#two-stage-generation)
    - [One-stage Generation](#one-stage-generation)
- [Datasets](#datasets)
    - [Indoor Datasets](#indoor-datasets)
    - [Natural Datasets](#natural-datasets)
    - [Urban Datasets](#urban-datasets)
- [Applications and Tasks](#applications-and-tasks)
  - [3D Scene Editing](#3d-scene-editing)
  - [Human-Scene Interaction](#human-scene-interaction)
  - [Embodied AI](#embodied-ai)
  - [Robotics](#robotics)
  - [Autonomous Driving](#autonomous-driving)

# Methods: A Hierarchical Taxonomy

## Procedural Generation

### Rule-based Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 1988 | SIGGRAPH |  | [Terrain simulation using a model of stream erosion](https://doi.org/10.1145/378456.378519) |  |  |
| 1989 | SIGGRAPH |  | [The synthesis and rendering of eroded fractal terrains](https://doi.org/10.1145/74334.74337) |  |  |
| 1993 | Graphics Interface |  | [A fractal model of mountains and rivers](https://doi.org/10.20380/GI1993.26) | [![link](https://img.shields.io/badge/Website-9cf)](https://algorithmicbotany.org/papers/mountains.gi93.html) |  |
| 1998 | SIGGRAPH |  | [Realistic modeling and rendering of plant ecosystems](https://doi.org/10.1145/280814.280898) | [![link](https://img.shields.io/badge/Website-9cf)](https://algorithmicbotany.org/papers/ecosys.sig98.html) |  |
| 2001 | SIGGRAPH | CityEngine | [Procedural modeling of cities](https://doi.org/10.1145/383259.383292) |  |  |
| 2005 | VRST |  | [Modeling Landscapes with Ridges and Rivers](https://doi.org/10.1145/1101616.1101648) |  |  |
| 2006 | TOG |  | [Procedural modeling of buildings](https://doi.org/10.1145/1141911.1141931) |  |  |
| 2007 | GDTW | Citygen | [Citygen: An Interactive System for Procedural City Generation](https://www.citygen.net/files/citygen_gdtw07.pdf) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.citygen.net/2007/12/GDTW-Paper) |  |
| 2007 | I3D |  | [Example-based model synthesis](https://doi.org/10.1145/1230100.1230119) | [![link](https://img.shields.io/badge/Website-9cf)](https://paulmerrell.org/model-synthesis) | [![GitHub](https://img.shields.io/github/stars/merrell42/model-synthesis)](https://github.com/merrell42/model-synthesis) |
| 2007 | TVCG |  | [Terrain Synthesis from Digital Elevation Models](https://doi.org/10.1109/TVCG.2007.1027) | [![link](https://img.shields.io/badge/Website-9cf)](http://terrainsynthesis.org/) |  |
| 2008 | TOG |  | [Continuous model synthesis](https://doi.org/10.1145/1409060.1409111) | [![link](https://img.shields.io/badge/Website-9cf)](http://gamma.cs.unc.edu/synthesis/) |  |
| 2009 | CGF |  | [Arches: a Framework for Modeling Complex Terrains](https://doi.org/10.1111/j.1467-8659.2009.01385.x) |  |  |
| 2009 | CGF |  | [Interactive Geometric Simulation of 4D Cities](https://doi.org/10.1111/j.1467-8659.2009.01387.x) |  |  |
| 2009 | TOG |  | [Interactive design of urban spaces using geometrical and behavioral modeling](https://doi.org/10.1145/1618452.1618457) | [![youtube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=youtube)](https://youtu.be/iR-UObGJ2Gs) |  |
| 2011 | SI3D |  | [Urban Ecosystem Design](https://doi.org/10.1145/1944745.1944773) |  |  |
| 2011 | TOG |  | [Metropolis procedural modeling](https://doi.org/10.1145/1944846.1944851) | [![link](https://img.shields.io/badge/Website-9cf)](https://vladlen.info/publications/metropolis-procedural-modeling/) |  |
| 2012 | TOG |  | [Inverse design of urban procedural models](https://doi.org/10.1145/2366145.2366187) | [![link](https://img.shields.io/badge/Website-9cf)](http://www.ignaciogarciadorado.com/p/2012_SIGA/2012_SIGA.html) |  |
| 2013 | TOG |  | [Terrain Generation Using Procedural Models Based on Hydrology](https://doi.org/10.1145/2461912.2461996) | [![youtube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=youtube&)](https://youtu.be/JCsj0v-wmIM) |  |
| 2015 | TOG | WorldBrush | [WorldBrush: Interactive Example-Based Synthesis of Procedural Virtual Worlds](https://doi.org/10.1145/2766975) | [![link](https://img.shields.io/badge/Website-9cf)](https://team.inria.fr/imagine/worldbrush-interactive-example-based-synthesis-of-procedural-virtual-worlds/) |  |
| 2016 | CGF |  | [Example-Driven Procedural Urban Roads](https://doi.org/10.1111/cgf.12728) |  |  |
| 2016 | 3DV |  | [Proceduralization for Editing 3D Architectural Models](https://doi.org/10.1109/3DV.2016.28) |  |  |
| 2017 | TOG |  | [Authoring landscapes by combining ecosystem and terrain erosion simulation](https://doi.org/10.1145/3072959.3073667) |  |  |
| 2019 | TOG |  | [Synthetic silviculture: multi-scale modeling of plant ecosystems](https://doi.org/10.1145/3306346.3323039) | [![link](https://img.shields.io/badge/Website-9cf)](https://storage.googleapis.com/pirk.io/projects/synthetic_silviculture/index.html) |  |
| 2021 | TOG |  | [Authoring Consistent Landscapes with Flora and Fauna](https://doi.org/10.1145/3450626.3459952) | [![link](https://img.shields.io/badge/Website-9cf)](https://www-sop.inria.fr/reves/Basilic/2021/ECCMMBC21/)  |  |
| 2022 | TOG | Ecoclimates | [Ecoclimates: Climate-Response Modeling of Vegetation](https://doi.org/10.1145/3528223.3530146) | [![link](https://img.shields.io/badge/Website-9cf)](https://storage.googleapis.com/pirk.io/projects/ecoclimates/) |  |
| 2023 | CVPR | Infinigen | [Infinite Photorealistic Worlds using Procedural Generation](https://arxiv.org/abs/2306.09310) | [![link](https://img.shields.io/badge/Website-9cf)](https://infinigen.org/) | [![GitHub](https://img.shields.io/github/stars/princeton-vl/infinigen)](https://github.com/princeton-vl/infinigen) |
| 2023 | TOG |  | [Forming Terrains by Glacial Erosion](https://doi.org/10.1145/3592422) | [![link](https://img.shields.io/badge/Website-9cf)](https://www-sop.inria.fr/reves/Basilic/2023/CJPBCBGGG23/) |  |
| 2023 | TOG |  | [Large-scale terrain authoring through interactive erosion simulation](https://doi.org/10.1145/3592787) | [![youtube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=youtube&)](https://youtu.be/gCP7jzcPLyQ) |  [![GitHub](https://img.shields.io/github/stars/H-Schott/StreamPowerErosion)](https://github.com/H-Schott/StreamPowerErosion) |
| 2023 | TOG |  | [Authoring and Simulating Meandering Rivers](https://doi.org/10.1145/3618350) | [![link](https://img.shields.io/badge/Website-9cf)](https://aparis69.github.io/public_html/projects/paris2023_Meanders.html) | [![GitHub](https://img.shields.io/github/stars/aparis69/Meandering-rivers)](https://aparis69.github.io/public_html/projects/paris2023_Meanders.html) |

### Optimization-based Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2002 | Graphics Interface |  | [Constraint-based Automatic Placement for Scene Composition](https://doi.org/10.20380/GI2002.04) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.dgp.toronto.edu/~kenxu/caps.html) |  |
| 2010 | TOG |  | [Computer-Generated Residential Building Layouts](https://doi.org/10.1145/1866158.1866203) | [![link](https://img.shields.io/badge/Website-9cf)](https://vladlen.info/publications/computer-generated-residential-building-layouts/) |  |
| 2011 | SIGGRAPH |  | [Interactive Furniture Layout Using Interior Design Guidelines](https://doi.org/10.1145/1964921.1964982) | [![link](https://img.shields.io/badge/Website-9cf)](https://graphics.stanford.edu/projects/furniture/) |  |
| 2011 | SIGGRAPH | Make it home | [Make it home: automatic optimization of furniture arrangement](https://doi.org/10.1145/1964921.1964981) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.saikit.org/static/projects/furniture/) |  |
| 2012 | TOG |  | [Example-based synthesis of 3D object arrangements](https://doi.org/10.1145/2366145.2366154) | [![link](https://img.shields.io/badge/Website-9cf)](https://graphics.stanford.edu/projects/scenesynth/) |  |
| 2015 | TVCG | Clutterpalette | [The Clutterpalette: An Interactive Tool for Detailing Indoor Scenes](https://doi.org/10.1109/TVCG.2015.2417575) | [![link](https://img.shields.io/badge/Website-9cf)](https://craigyuyu.github.io/home/project_pages/clutterpalette/) |  |
| 2018 | CGF |  | [MIQP-based Layout Design for Building Interiors](https://doi.org/10.1111/cgf.13380) | [![link](https://img.shields.io/badge/Website-9cf)](https://wutomwu.github.io/particulars.html?id=0) |  |
| 2018 | CVPR |  | [Human-centric Indoor Scene Synthesis Using Stochastic Grammar](https://arxiv.org/abs/1808.08473) |  | [![GitHub](https://img.shields.io/github/stars/SiyuanQi-zz/human-centric-scene-synthesis)](https://github.com/SiyuanQi-zz/human-centric-scene-synthesis) |
| 2018 | VR |  | [Automatic Furniture Arrangement Using Greedy Cost Minimization](https://doi.org/10.1109/VR.2018.8448291) | [![youtube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=youtube&)](https://youtu.be/Wd69_jpTczk) | [![GitHub](https://img.shields.io/github/stars/usama2762/Furniture-Optimization)](https://github.com/usama2762/Furniture-Optimization) |
| 2021 | MM | MageAdd | [MageAdd: Real-Time Interaction Simulation for Scene Synthesis](https://doi.org/10.1145/3474085.3475194) |  | [![GitHub](https://img.shields.io/github/stars/Shao-Kui/3DScenePlatform)](https://github.com/Shao-Kui/3DScenePlatform#mageadd) |
| 2021 | TVCG |  | [Fast 3D Indoor Scene Synthesis by Learning Spatial Relation Priors of Objects](https://doi.org/10.1109/TVCG.2021.3050143) |  |  |
| 2021 | arXiv | LUMINOUS | [LUMINOUS: Indoor Scene Generation for Embodied AI Challenges](https://arxiv.org/abs/2111.05527) |  | [![GitHub](https://img.shields.io/github/stars/amazon-science/indoor-scene-generation-eai)](https://github.com/amazon-science/indoor-scene-generation-eai) |
| 2022 | NeurIPS | ProcTHOR | [ProcTHOR: Large-Scale Embodied AI Using Procedural Generation](https://arxiv.org/abs/2206.06994) | [![link](https://img.shields.io/badge/Website-9cf)](https://procthor.allenai.org/) | [![GitHub](https://img.shields.io/github/stars/allenai/procthor)](https://github.com/allenai/procthor) |
| 2024 | CVPR | Infinigen Indoors | [Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation](https://arxiv.org/abs/2406.11824) | [![link](https://img.shields.io/badge/Website-9cf)](https://infinigen.org/) | [![GitHub](https://img.shields.io/github/stars/princeton-vl/infinigen)](https://github.com/princeton-vl/infinigen) |

### LLM-based Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2023 | NeurIPS | LayoutGPT | [LayoutGPT: Compositional Visual Planning and Generation with Large Language Models](https://arxiv.org/abs/2305.15393) | [![link](https://img.shields.io/badge/Website-9cf)](https://layoutgpt.github.io/) | [![GitHub](https://img.shields.io/github/stars/weixi-feng/LayoutGPT)](https://github.com/weixi-feng/LayoutGPT) |
| 2024 | CVPR | GraphDreamer | [GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs](https://arxiv.org/abs/2312.00093) | [![link](https://img.shields.io/badge/Website-9cf)](https://graphdreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/GGGHSL/GraphDreamer)](https://github.com/GGGHSL/GraphDreamer) |
| 2024 | ECCV | AnyHome | [AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes](https://arxiv.org/abs/2312.06644) | [![link](https://img.shields.io/badge/Website-9cf)](https://ivl.cs.brown.edu/research/anyhome) | [![GitHub](https://img.shields.io/github/stars/FreddieRao/anyhome_github)](https://github.com/FreddieRao/anyhome_github) |
| 2024 | ECCV | SceneTeller | [SceneTeller: Language-to-3D Scene Generation](https://arxiv.org/abs/2407.20727) | [![link](https://img.shields.io/badge/Website-9cf)](https://sceneteller.github.io/) | [![GitHub](https://img.shields.io/github/stars/sceneteller/SceneTeller)](https://github.com/sceneteller/SceneTeller) |
| 2024 | ICML | SceneCraft | [SceneCraft: An LLM Agent for Synthesizing 3D Scenes as Blender Code](https://arxiv.org/abs/2403.01248) |  |  |
| 2024 | MM |  | [Controllable Procedural Generation of Landscapes](https://doi.org/10.1145/3664647.3681129) |  | [![GitHub](https://img.shields.io/github/stars/omegafantasy/ControllableLandscape)](https://github.com/omegafantasy/ControllableLandscape) |
| 2024 | SIGGRAPH Asia | DIScene | [DIScene: Object Decoupling and Interaction Modeling for Complex Scene Generation](https://doi.org/10.1145/3680528.3687589) | [![link](https://img.shields.io/badge/Video-23FF0000)](https://dl.acm.org/doi/10.1145/3680528.3687589#supplementary-materials) |  |
| 2024 | arXiv |  | [Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases](https://arxiv.org/abs/2403.09675) |  |  |
| 2024 | arXiv | I-Design | [I-Design: Personalized LLM Interior Designer](https://arxiv.org/abs/2404.02838) | [![link](https://img.shields.io/badge/Website-9cf)](https://atcelen.github.io/I-Design/) | [![GitHub](https://img.shields.io/github/stars/atcelen/IDesign)](https://github.com/atcelen/IDesign/) |
| 2024 | arXiv | LLplace | [LLplace: The 3D Indoor Scene Layout Generation and Editing via Large Language Model](https://arxiv.org/abs/2406.03866) |  |  |
| 2024 | arXiv | CityCraft | [CityCraft: A Real Crafter for 3D City Generation](https://arxiv.org/abs/2406.04983) |  | [![GitHub](https://img.shields.io/github/stars/djFatNerd/CityCraft)](https://github.com/djFatNerd/CityCraft) |
| 2024 | arXiv | CityX | [CityX: Controllable Procedural Content Generation for Unbounded 3D Cities](https://arxiv.org/abs/2407.17572) | [![link](https://img.shields.io/badge/Website-9cf)](https://cityx-lab.github.io/) | [![GitHub](https://img.shields.io/github/stars/cityx-lab/CityX-Lab)](https://github.com/cityx-lab/CityX-Lab) |
| 2024 | arXiv | GraphCanvas3D | [Graph Canvas for Controllable 3D Scene Generation](https://arxiv.org/abs/2412.00091) |  |  |
| 2025 | 3DV | 3D-GPT | [3D-GPT: Procedural 3D Modeling with Large Language Models](https://arxiv.org/abs/2310.12945) | [![link](https://img.shields.io/badge/Website-9cf)](https://chuny1.github.io/3DGPT/3dgpt.html) | [![GitHub](https://img.shields.io/github/stars/Chuny1/3DGPT)](https://github.com/Chuny1/3DGPT) |
| 2025 | AAAI | SceneX | [SceneX: Procedural Controllable Large-scale Scene Generation](https://arxiv.org/abs/2403.15698) | [![link](https://img.shields.io/badge/Website-9cf)](https://zhouzq1.github.io/SceneX/) | [![GitHub](https://img.shields.io/github/stars/zhouzq1/SceneX)](https://github.com/zhouzq1/SceneX) |
| 2025 | AAAI |  | [Hierarchically-Structured Open-Vocabulary Indoor Scene Synthesis with Pre-trained Large Language Model](https://arxiv.org/abs/2502.10675) |  | [![GitHub](https://img.shields.io/github/stars/SunWeiLin-Lynne/Hierarchically-Structured-Open-Vocabulary-Indoor-Scene-Synthesis)](https://github.com/SunWeiLin-Lynne/Hierarchically-Structured-Open-Vocabulary-Indoor-Scene-Synthesis) |
| 2025 | CVPR |  | [Global-Local Tree Search in VLMs for 3D Indoor Scene Generation](https://arxiv.org/abs/2503.18476) |  | [![GitHub](https://img.shields.io/github/stars/dw-dengwei/TreeSearchGen)](https://github.com/dw-dengwei/TreeSearchGen) |
| 2025 | CVPR | LayoutVLM | [LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models](https://arxiv.org/abs/2412.02193) | [![link](https://img.shields.io/badge/Website-9cf)](https://ai.stanford.edu/~sunfanyun/layoutvlm/) | [![GitHub](https://img.shields.io/github/stars/sunfanyunn/LayoutVLM)](https://github.com/sunfanyunn/LayoutVLM) |
| 2025 | CVPR | The Scene Language | [The Scene Language: Representing Scenes with Programs, Words, and Embeddings](https://arxiv.org/abs/2410.16770) | [![link](https://img.shields.io/badge/Website-9cf)](https://ai.stanford.edu/~yzzhang/projects/scene-language/) | [![GitHub](https://img.shields.io/github/stars/zzyunzhi/scene-language)](https://github.com/zzyunzhi/scene-language) |
| 2025 | arXiv | WorldCraft | [WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents](https://arxiv.org/abs/2502.15601) |  |  |
| 2025 | arXiv | Cube | [Cube: A Roblox View of 3D Intelligence](https://arxiv.org/abs/2503.15475) |  | [![GitHub](https://img.shields.io/github/stars/Roblox/cube)](https://github.com/Roblox/cube) |
| 2025 | arXiv | Scenethesis | [Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](https://arxiv.org/abs/2505.02836) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/dir/scenethesis/) |  |
| 2025 | arXiv |  | [Agentic 3D Scene Generation with Spatially Contextualized VLMs](https://arxiv.org/abs/2505.20129) |  |  |

## Neural-3D Generation

### Scene Parameters

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2018 | SIGGRAPH | DeepSynth | [Deep Convolutional Priors for Indoor Scene Synthesis](https://doi.org/10.1145/3197517.3201362) | [![link](https://img.shields.io/badge/Website-9cf)](https://doi.org/10.1145/3197517.3201362) | [![GitHub](https://img.shields.io/github/stars/brownvc/deep-synth)](https://github.com/brownvc/deep-synth) |
| 2019 | CVPR | FastSynth | [Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models](https://arxiv.org/abs/1811.12463) |  | [![GitHub](https://img.shields.io/github/stars/brownvc/fast-synth)](https://github.com/brownvc/fast-synth) |
| 2020 | SIGGRAPH |  | [Deep Generative Modeling for Scene Synthesis via Hybrid Representations](https://arxiv.org/abs/1808.02084) |  |  |
| 2021 | 3DV | SceneFormer | [SceneFormer: Indoor Scene Generation with Transformers](https://arxiv.org/abs/2012.09793) | [![link](https://img.shields.io/badge/Website-9cf)](https://xinpeng-wang.github.io/sceneformer/) | [![GitHub](https://img.shields.io/github/stars/cy94/sceneformer)](https://github.com/cy94/sceneformer) |
| 2021 | ICCV | Sync2Gen | [Scene Synthesis via Uncertainty-Driven Attribute Synchronization](https://arxiv.org/abs/2108.13499) |  | [![GitHub](https://img.shields.io/github/stars/yanghtr/Sync2Gen)](https://github.com/yanghtr/Sync2Gen) |
| 2021 | NeurIPS | ATISS | [ATISS: Autoregressive Transformers for Indoor Scene Synthesis](https://arxiv.org/abs/2110.03675) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/ATISS/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/atiss)](https://github.com/nv-tlabs/atiss) |
| 2022 | ECCV | Pose2Room | [Pose2Room: Understanding 3D Scenes from Human Activities](https://arxiv.org/abs/2112.03030) | [![link](https://img.shields.io/badge/Website-9cf)](https://yinyunie.github.io/pose2room-page/) | [![GitHub](https://img.shields.io/github/stars/yinyunie/pose2room)](https://github.com/yinyunie/pose2room) |
| 2022 | SIGGRAPH Asia | SUMMON | [Scene Synthesis from Human Motion](https://arxiv.org/abs/2301.01424) | [![link](https://img.shields.io/badge/Website-9cf)](https://lijiaman.github.io/projects/summon/) | [![GitHub](https://img.shields.io/github/stars/onestarYX/summon)](https://github.com/onestarYX/summon) |
| 2023 | CVPR |  | [Learning 3D Scene Priors with 2D Supervision](https://arxiv.org/abs/2211.14157) | [![link](https://img.shields.io/badge/Website-9cf)](https://yinyunie.github.io/sceneprior-page/) | [![GitHub](https://img.shields.io/github/stars/yinyunie/ScenePriors)](https://github.com/yinyunie/ScenePriors) |
| 2023 | CVPR | MIME | [MIME: Human-Aware 3D Scene Generation](https://arxiv.org/abs/2212.04360) | [![link](https://img.shields.io/badge/Website-9cf)](https://mime.is.tue.mpg.de/) | [![GitHub](https://img.shields.io/github/stars/yhw-yhw/MIME)](https://github.com/yhw-yhw/MIME) |
| 2023 | SIGGRAPH | COFS | [COFS: COntrollable Furniture layout Synthesis](https://doi.org/10.1145/3588432.3591561) |  |  |
| 2023 | NeurIPS |  | [Language-driven Scene Synthesis using Multi-conditional Diffusion Model](https://arxiv.org/abs/2310.15948) | [![link](https://img.shields.io/badge/Website-9cf)](https://lang-scene-synth.github.io/) | [![GitHub](https://img.shields.io/github/stars/andvg3/LSDM)](https://github.com/andvg3/LSDM) |
| 2024 | 3DV | RoomDesigner | [RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation](https://arxiv.org/abs/2310.10027) |  | [![GitHub](https://img.shields.io/github/stars/zhao-yiqun/RoomDesigner)](https://github.com/zhao-yiqun/RoomDesigner) |
| 2024 | CVPR | DiffuScene | [DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis](https://arxiv.org/abs/2303.14207) | [![link](https://img.shields.io/badge/Website-9cf)](https://tangjiapeng.github.io/projects/DiffuScene/) | [![GitHub](https://img.shields.io/github/stars/tangjiapeng/DiffuScene)](https://github.com/tangjiapeng/DiffuScene) |
| 2024 | CVPR | SceneWiz3D | [SceneWiz3D: Towards Text-guided 3D Scene Composition](https://arxiv.org/abs/2312.08885) | [![link](https://img.shields.io/badge/Website-9cf)](https://zqh0253.github.io/SceneWiz3D/) | [![GitHub](https://img.shields.io/github/stars/zqh0253/SceneWiz3D)](https://github.com/zqh0253/SceneWiz3D) |
| 2024 | CVPR | PhyScene | [PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI](https://arxiv.org/abs/2404.09465) | [![link](https://img.shields.io/badge/Website-9cf)](https://physcene.github.io/) | [![GitHub](https://img.shields.io/github/stars/PhyScene/PhyScene)](https://github.com/PhyScene/PhyScene) |
| 2024 | ECCV | DreamScene | [DreamScene: 3D Gaussian-Based Text-to-3D Scene Generation via Formation Pattern Sampling](https://arxiv.org/abs/2404.03575) | [![link](https://img.shields.io/badge/Website-9cf)](https://dreamscene-project.github.io/) | [![GitHub](https://img.shields.io/github/stars/DreamScene-Project/DreamScene)](https://github.com/DreamScene-Project/DreamScene) |
| 2024 | ICML | GALA3D | [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://arxiv.org/abs/2402.07207) | [![link](https://img.shields.io/badge/Website-9cf)](https://gala3d.github.io/) | [![GitHub](https://img.shields.io/github/stars/VDIGPKU/GALA3D)](https://github.com/VDIGPKU/GALA3D) |
| 2024 | ICML |  | [Disentangled 3D Scene Generation with Layout Learning](https://arxiv.org/abs/2402.16936) | [![link](https://img.shields.io/badge/Website-9cf)](https://dave.ml/layoutlearning/) |  |
| 2024 | MM | RelScene | [RelScene: A Benchmark and baseline for Spatial Relations in text-driven 3D Scene Generation](https://openreview.net/forum?id=GIw7pmMPPX) |  |  |
| 2024 | NeurIPS | DeBaRA | [DeBaRA: Denoising-Based 3D Room Arrangement Generation](https://arxiv.org/abs/2409.18336) |  |  |
| 2024 | SIGGRAPH | INFERACT | [Physics-based Scene Layout Generation From Human Motion](https://arxiv.org/abs/2405.12460) | [![link](https://img.shields.io/badge/Website-9cf)](https://jiann-li.github.io/physcenegen/) |  |
| 2024 | arXiv | Lay-A-Scene | [Lay-A-Scene: Personalized 3D Object Arrangement Using Text-to-Image Priors](https://arxiv.org/abs/2406.00687) | [![link](https://img.shields.io/badge/Website-9cf)](https://lay-a-scene.github.io/) | [![GitHub](https://img.shields.io/github/stars/ohad204/Lay-A-Scene)](https://github.com/ohad204/Lay-A-Scene) |
| 2025 | 3DV | Ctrl-Room | [Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints](https://arxiv.org/abs/2310.03602) | [![link](https://img.shields.io/badge/Website-9cf)](https://fangchuan.github.io/ctrl-room.github.io/) | [![GitHub](https://img.shields.io/github/stars/fangchuan/Ctrl-Room)](https://github.com/fangchuan/Ctrl-Room) |
| 2025 | CVPR | SceneFactor | [SceneFactor: Factored Latent 3D Diffusion for Controllable 3D Scene Generation](https://arxiv.org/abs/2412.01801) | [![link](https://img.shields.io/badge/Website-9cf)](https://alexeybokhovkin.github.io/scenefactor/) | [![GitHub](https://img.shields.io/github/stars/alexeybokhovkin/SceneFactor)](https://github.com/alexeybokhovkin/SceneFactor) |
| 2025 | CVPR | CASAGPT | [CASAGPT: Cuboid Arrangement and Scene Assembly for Interior Design](https://arxiv.org/abs/2504.19478) |  | [![GitHub](https://img.shields.io/github/stars/CASAGPT/CASA-GPT?style=social)](https://github.com/CASAGPT/CASA-GPT) |
| 2025 | arXiv |  | [Steerable Scene Generation with Post Training and Inference-Time Search](https://arxiv.org/abs/2505.04831) | [![link](https://img.shields.io/badge/Website-9cf)](https://steerable-scene-generation.github.io/) | [![GitHub](https://img.shields.io/github/stars/nepfaff/steerable-scene-generation)](https://github.com/nepfaff/steerable-scene-generation) |

### Scene Graph

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2014 | EMNLP |  | [Learning Spatial Knowledge for Text to 3D Scene Generation](https://doi.org/10.3115/v1/D14-1217) |  |  |
| 2016 | CGF |  | [Learning 3D Scene Synthesis from Annotated RGB-D Images](https://doi.org/10.1111/cgf.12976) |  |  |
| 2017 | TOG |  | [Adaptive synthesis of indoor scenes via activity-associated object relation graphs](https://doi.org/10.1145/3130800.3130805) | [![youtube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=youtube)](https://youtu.be/KNAkgtaD6yM) |  |
| 2018 | TOG |  | [Language-Driven Synthesis of 3D Scenes from Scene Databases](https://doi.org/10.1145/3272127.3275035) | [![link](https://img.shields.io/badge/Website-9cf)](https://manyili12345.github.io/Publication/2018/T2S/index.html) |  |
| 2019 | ICCV | Meta-Sim | [Meta-Sim: Learning to Generate Synthetic Datasets](https://arxiv.org/abs/1904.11621) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/meta-sim/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/meta-sim)](https://github.com/nv-tlabs/meta-sim) |
| 2019 | SIGGRAPH | GRAINS | [GRAINS: Generative Recursive Autoencoders for INdoor Scenes](https://arxiv.org/abs/1807.09193) | [![link](https://img.shields.io/badge/Website-9cf)](https://manyili12345.github.io/Publication/2018/GRAINS/index.html) | [![GitHub](https://img.shields.io/github/stars/ManyiLi12345/GRAINS)](https://github.com/ManyiLi12345/GRAINS) |
| 2019 | SIGGRAPH | PlanIT | [PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks](https://doi.org/10.1145/3306346.3322941) |  | [![GitHub](https://img.shields.io/github/stars/brownvc/planit)](https://github.com/brownvc/planit) |
| 2020 | CVPR | 3D-SLN | [End-to-End Optimization of Scene Layout](https://arxiv.org/abs/2007.11744) | [![link](https://img.shields.io/badge/Website-9cf)](http://3dsln.csail.mit.edu/) | [![GitHub](https://img.shields.io/github/stars/aluo-x/3D_SLN)](https://github.com/aluo-x/3D_SLN) |
| 2020 | ECCV | Meta-Sim 2 | [Meta-Sim 2 Unsupervised Learning of Scene Structure for Synthetic Data Generation](https://arxiv.org/abs/2008.09092) | [![link](https://img.shields.io/badge/Website-9cf)](https://amlankar.github.io/publication/meta-sim2/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/meta-sim-structure)](https://github.com/nv-tlabs/meta-sim-structure) |
| 2021 | ICCV | Graph-to-3D | [Graph-to-3D: End-to-End Generation and Manipulation of 3D Scenes Using Scene Graphs](https://arxiv.org/abs/2108.08841) | [![link](https://img.shields.io/badge/Website-9cf)](https://he-dhamo.github.io/Graphto3D/) | [![GitHub](https://img.shields.io/github/stars/he-dhamo/graphto3d)](https://github.com/he-dhamo/graphto3d) |
| 2023 | NeurIPS | CommonScenes | [CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph Diffusion](https://arxiv.org/abs/2305.16283) | [![link](https://img.shields.io/badge/Website-9cf)](https://sites.google.com/view/commonscenes) | [![GitHub](https://img.shields.io/github/stars/ymxlzgy/commonscenes)](https://github.com/ymxlzgy/commonscenes) |
| 2023 | TPAMI | SceneHGN | [SceneHGN: Hierarchical Graph Networks for 3D Indoor Scene Generation With Fine-Grained Geometry](https://arxiv.org/abs/2302.10237) | [![link](https://img.shields.io/badge/Website-9cf)](http://geometrylearning.com/scenehgn/) | [![GitHub](https://img.shields.io/github/stars/tommaoer/SceneHGN)](https://github.com/tommaoer/SceneHGN) |
| 2024 | ECCV | SEK | [External Knowledge Enhanced 3D Scene Generation from Sketch](https://arxiv.org/abs/2403.14121) |  |  |
| 2024 | ECCV | Forest2Seq | [Forest2Seq: Revitalizing Order Prior for Sequential Indoor Scene Synthesis](https://arxiv.org/abs/2407.05388) |  |  |
| 2024 | ECCV | EchoScene | [EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion](https://arxiv.org/abs/2405.00915) | [![link](https://img.shields.io/badge/Website-9cf)](https://sites.google.com/view/echoscene) | [![GitHub](https://img.shields.io/github/stars/ymxlzgy/echoscene)](https://github.com/ymxlzgy/echoscene) |
| 2024 | ICLR | InstructScene | [InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior](https://arxiv.org/abs/2402.04717) | [![link](https://img.shields.io/badge/Website-9cf)](https://chenguolin.github.io/projects/InstructScene/) | [![GitHub](https://img.shields.io/github/stars/chenguolin/InstructScene)](https://github.com/chenguolin/InstructScene) |
| 2025 | AAAI | MMGDreamer | [MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation](https://arxiv.org/abs/2502.05874) | [![link](https://img.shields.io/badge/Website-9cf)](https://yangzhifeio.github.io/project/MMGDreamer/) | [![GitHub](https://img.shields.io/github/stars/yangzhifeio/MMGDreamer?style=social)](https://github.com/yangzhifeio/MMGDreamer) |
| 2025 | arXiv |  | [Controllable 3D Outdoor Scene Generation via Scene Graphs](https://arxiv.org/abs/2503.07152) |  | [![GitHub](https://img.shields.io/github/stars/yuhengliu02/control-3d-scene)](https://github.com/yuhengliu02/control-3d-scene) |
| 2025 | arXiv | HiScene | [HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation](https://arxiv.org/abs/2504.13072) | [![link](https://img.shields.io/badge/Website-9cf)](https://zju3dv.github.io/hiscene/) |  |


### Semantic Layout

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2021 | ICCV | SGSDI | [Indoor Scene Generation from a Collection of Semantic-Segmented Depth Images](https://arxiv.org/abs/2108.09022) | [![link](https://img.shields.io/badge/Website-9cf)](https://github.com/microsoft/SGSDI/) | [![GitHub](https://img.shields.io/github/stars/microsoft/SGSDI)](https://github.com/microsoft/SGSDI/) |
| 2021 | ICCV | GANcraft | [GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds](https://arxiv.org/abs/2104.07659) | [![link](https://img.shields.io/badge/Website-9cf)](https://nvlabs.github.io/GANcraft/) | [![GitHub](https://img.shields.io/github/stars/NVlabs/imaginaire)](https://github.com/NVlabs/imaginaire) |
| 2023 | CVPR | DisCoScene | [DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis](https://arxiv.org/abs/2212.11984) | [![link](https://img.shields.io/badge/Website-9cf)](https://snap-research.github.io/discoscene/) | [![GitHub](https://img.shields.io/github/stars/snap-research/discoscene)](https://github.com/snap-research/discoscene) |
| 2023 | ICCV | InfiniCity | [InfiniCity: Infinite-Scale City Synthesis](https://arxiv.org/abs/2301.09637) | [![link](https://img.shields.io/badge/Website-9cf)](https://hubert0527.github.io/infinicity/) |  |
| 2023 | ICCV | CC3D | [CC3D: Layout-Conditioned Generation of Compositional 3D Scenes](https://arxiv.org/abs/2303.12074) | [![link](https://img.shields.io/badge/Website-9cf)](https://sherwinbahmani.github.io/cc3d/) | [![GitHub](https://img.shields.io/github/stars/sherwinbahmani/cc3d)](https://github.com/sherwinbahmani/cc3d) |
| 2023 | ICCV | Set-the-Scene | [Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes](https://arxiv.org/abs/2303.13450) | [![link](https://img.shields.io/badge/Website-9cf)](https://danacohen95.github.io/Set-the-Scene/) | [![GitHub](https://img.shields.io/github/stars/DanaCohen95/Set-the-Scene)](https://github.com/DanaCohen95/Set-the-Scene) |
| 2023 | ICCV | UrbanGIRAFFE | [UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative Neural Feature Fields](https://arxiv.org/abs/2303.14167) | [![link](https://img.shields.io/badge/Website-9cf)](https://lv3d.github.io/urbanGIRAFFE/) | [![GitHub](https://img.shields.io/github/stars/freemty/urbanGIRAFFE)](https://github.com/freemty/urbanGIRAFFE) |
| 2023 | TPAMI | SceneDreamer | [SceneDreamer: Unbounded 3D Scene Generation From 2D Image Collections](https://arxiv.org/abs/2302.01330) | [![link](https://img.shields.io/badge/Website-9cf)](https://scene-dreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/FrozenBurning/SceneDreamer)](https://github.com/FrozenBurning/SceneDreamer) |
| 2023 | arXiv | CompoNeRF | [CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout](https://arxiv.org/abs/2303.13843) | [![link](https://img.shields.io/badge/Website-9cf)](https://vlislab22.github.io/componerf/) | [![GitHub](https://img.shields.io/github/stars/hbai98/Componerf)](https://github.com/hbai98/Componerf) |
| 2024 | 3DV | Comp3D | [Compositional 3D Scene Generation using Locally Conditioned Diffusion](https://arxiv.org/abs/2303.12218) | [![link](https://img.shields.io/badge/Website-9cf)](https://ryanpo.com/comp3d/) |  |
| 2024 | CVPR | CityDreamer | [CityDreamer: Compositional Generative Model of Unbounded 3D Cities](https://arxiv.org/abs/2309.00610) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.infinitescript.com/project/city-dreamer/) | [![GitHub](https://img.shields.io/github/stars/hzxie/CityDreamer)](https://github.com/hzxie/CityDreamer) |
| 2024 | CVPR | BerfScene | [BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation](https://arxiv.org/abs/2312.02136) | [![link](https://img.shields.io/badge/Website-9cf)](https://zqh0253.github.io/BerfScene/) | [![GitHub](https://img.shields.io/github/stars/zqh0253/BerfScene)](https://github.com/zqh0253/BerfScene) |
| 2024 | NeurIPS | SceneCraft | [SceneCraft: Layout-Guided 3D Scene Generation](https://arxiv.org/abs/2410.09049) | [![link](https://img.shields.io/badge/Website-9cf)](https://orangesodahub.github.io/SceneCraft/) | [![GitHub](https://img.shields.io/github/stars/OrangeSodahub/SceneCraft)](https://github.com/OrangeSodahub/SceneCraft) |
| 2024 | SIGGRAPH | BlockFusion | [BlockFusion: Expandable 3D Scene Generation Using Latent Tri-plane Extrapolation](https://arxiv.org/abs/2401.17053) | [![link](https://img.shields.io/badge/Website-9cf)](https://yang-l1.github.io/blockfusion/) | [![GitHub](https://img.shields.io/github/stars/Tencent/BlockFusion)](https://github.com/Tencent/BlockFusion) |
| 2024 | SIGGRAPH Asia | Frankenstein | [Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane](https://arxiv.org/abs/2403.16210) | [![link](https://img.shields.io/badge/Website-9cf)](https://wolfball.github.io/frankenstein/) | [![GitHub](https://img.shields.io/github/stars/Tencent/Frankenstein)](https://github.com/Tencent/Frankenstein) |
| 2024 | arXiv | Urban Architect | [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](https://arxiv.org/abs/2404.06780) | [![link](https://img.shields.io/badge/Website-9cf)](https://urbanarchitect.github.io) | [![GitHub](https://img.shields.io/github/stars/UrbanArchitect/UrbanArchitect)](https://github.com/UrbanArchitect/UrbanArchitect) |
| 2025 | CVPR | GaussianCity | [Generative Gaussian Splatting for Unbounded 3D City Generation](https://arxiv.org/abs/2406.06526) | [![link](https://img.shields.io/badge/Website-9cf)](https://haozhexie.com/project/gaussian-city) | [![GitHub](https://img.shields.io/github/stars/hzxie/GaussianCity)](https://github.com/hzxie/GaussianCity) |
| 2025 | ICLR | Layout-your-3D | [Layout-your-3D: Controllable and Precise 3D Generation with 2D Blueprint](https://arxiv.org/abs/2410.15391) | [![link](https://img.shields.io/badge/Website-9cf)](https://colezwhy.github.io/layoutyour3d/) | [![GitHub](https://img.shields.io/github/stars/Colezwhy/Layout-Your-3D)](https://github.com/Colezwhy/Layout-Your-3D) |
| 2025 | arXiv | Layout2Scene | [Layout2Scene: 3D Semantic Layout Guided Scene Generation via Geometry and Appearance Diffusion Priors](https://arxiv.org/abs/2501.02519) |  |  |
| 2025 | arXiv | CityDreamer4D | [CityDreamer4D: Compositional Generative Model of Unbounded 4D Cities](https://arxiv.org/abs/2501.08983) | [![link](https://img.shields.io/badge/Website-9cf)](https://haozhexie.com/project/city-dreamer-4d) | [![GitHub](https://img.shields.io/github/stars/hzxie/CityDreamer4D)](https://github.com/hzxie/CityDreamer4D) |

### Implicit Layout

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2021 | CVPR | GIRAFFE | [GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields](https://arxiv.org/abs/2011.12100) |  | [![GitHub](https://img.shields.io/github/stars/autonomousvision/giraffe)](https://github.com/autonomousvision/giraffe) |
| 2021 | ICCV | GSN | [Unconstrained Scene Generation With Locally Conditioned Radiance Fields](https://arxiv.org/abs/2104.00670) | [![link](https://img.shields.io/badge/Website-9cf)](https://apple.github.io/ml-gsn/) | [![GitHub](https://img.shields.io/github/stars/apple/ml-gsn)](https://github.com/apple/ml-gsn) |
| 2021 | ICML | NeRF-VAE | [NeRF-VAE: A geometry aware 3d scene generative model](https://arxiv.org/abs/2104.00587) |  |  |
| 2022 | NeurIPS | GAUDI | [GAUDI: A Neural Architect for Immersive 3D Scene Generation](https://arxiv.org/abs/2207.13751) |  | [![GitHub](https://img.shields.io/github/stars/apple/ml-gaudi)](https://github.com/apple/ml-gaudi) |
| 2023 | CVPR | Persistent Nature | [Persistent Nature: A generative model of unbounded 3D worlds](https://arxiv.org/abs/2303.13515) | [![link](https://img.shields.io/badge/Website-9cf)](https://chail.github.io/persistent-nature/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research)](https://github.com/google-research/google-research/tree/master/persistent-nature) |
| 2023 | CVPR | NeuralField-LDM | [NeuralField-LDM: Scene Generation with Hierarchical Latent Diffusion Models](https://arxiv.org/abs/2304.09787) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/NFLDM/) |  |
| 2023 | arXiv |  | [Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data](https://arxiv.org/abs/2301.00527) | [![link](https://img.shields.io/badge/Website-9cf)](https://github.com/zoomin-lee/scene-scale-diffusion) | [![GitHub](https://img.shields.io/github/stars/zoomin-lee/scene-scale-diffusion)](https://github.com/zoomin-lee/scene-scale-diffusion) |
| 2024 | CVPR | DiffInDScene | [DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation](https://arxiv.org/abs/2306.00519) | [![link](https://img.shields.io/badge/Website-9cf)](https://akirahero.github.io/diffindscene/) | [![GitHub](https://img.shields.io/github/stars/AkiraHero/diffindscene)](https://github.com/AkiraHero/diffindscene) |
| 2024 | CVPR | XCube | [XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies](https://arxiv.org/abs/2312.03806) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/xcube/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/XCube)](https://github.com/nv-tlabs/XCube) |
| 2024 | CVPR | SemCity | [SemCity: Semantic Scene Generation with Triplane Diffusion](https://arxiv.org/abs/2403.07773) | [![link](https://img.shields.io/badge/Website-9cf)](https://sglab.kaist.ac.kr/SemCity/) | [![GitHub](https://img.shields.io/github/stars/zoomin-lee/SemCity)](https://github.com/zoomin-lee/SemCity) |
| 2024 | ECCV | PDD | [Pyramid Diffusion for Fine 3D Large Scene Generation](https://arxiv.org/abs/2311.12085) | [![link](https://img.shields.io/badge/Website-9cf)](https://yuheng.ink/project-page/pyramid-discrete-diffusion/) | [![GitHub](https://img.shields.io/github/stars/yuhengliu02/pyramid-discrete-diffusion)](https://github.com/yuhengliu02/pyramid-discrete-diffusion) |
| 2024 | NeurIPS | Director3D | [Director3D: Real-world Camera Trajectory and 3D Scene Generation from Text](https://arxiv.org/abs/2406.17601) | [![link](https://img.shields.io/badge/Website-9cf)](https://imlixinyang.github.io/director3d-page/) | [![GitHub](https://img.shields.io/github/stars/imlixinyang/director3d)](https://github.com/imlixinyang/director3d) |
| 2025 | CVPR | LT3SD | [LT3SD: Latent Trees for 3D Scene Diffusion](https://arxiv.org/abs/2409.08215) | [![link](https://img.shields.io/badge/Website-9cf)](https://quan-meng.github.io/projects/lt3sd/) | [![GitHub](https://img.shields.io/github/stars/quan-meng/lt3sd)](https://github.com/quan-meng/lt3sd) |
| 2025 | CVPR | SplatFlow | [SplatFlow: Multi-View Rectified Flow Model for 3D Gaussian Splatting Synthesis](https://arxiv.org/abs/2411.16443) | [![link](https://img.shields.io/badge/Website-9cf)](https://gohyojun15.github.io/SplatFlow/) | [![GitHub](https://img.shields.io/github/stars/gohyojun15/SplatFlow?style=social)](https://github.com/gohyojun15/SplatFlow/) |
| 2025 | CVPR | Prometheus | [Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation](https://arxiv.org/abs/2412.21117) | [![link](https://img.shields.io/badge/Website-9cf)](https://freemty.github.io/project-prometheus/) | [![GitHub](https://img.shields.io/github/stars/XDimLab/Prometheus)](https://github.com/XDimLab/Prometheus) |
| 2025 | ICLR | DynamicCity | [DynamicCity: Large-Scale Occupancy Generation from Dynamic Scenes](https://arxiv.org/abs/2410.18084) | [![link](https://img.shields.io/badge/Website-9cf)](https://dynamic-city.github.io/) | [![GitHub](https://img.shields.io/github/stars/3DTopia/DynamicCity)](https://github.com/3DTopia/DynamicCity) |
| 2025 | arXiv | NuiScene | [NuiScene: Exploring Efficient Generation of Unbounded Outdoor Scenes](https://arxiv.org/abs/2503.16375) | [![link](https://img.shields.io/badge/Website-9cf)](https://3dlg-hcvc.github.io/NuiScene/) | [![GitHub](https://img.shields.io/github/stars/3dlg-hcvc/NuiScene?style=social)](https://github.com/3dlg-hcvc/NuiScene) |

## Image-based Generation

### Holistic Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2019 | ICIP |  | [360-Degree Image Completion by Two-Stage Conditional Gans](https://doi.org/10.1109/ICIP.2019.8803435) |  |  |
| 2020 | CVPR | Sat2Ground | [Geometry-Aware Satellite-to-Ground Image Synthesis for Urban Areas](https://doi.org/10.1109/CVPR42600.2020.00094) |  | [![GitHub](https://img.shields.io/github/stars/lizuoyue/sate_to_ground)](https://github.com/lizuoyue/sate_to_ground) |
| 2020 | WACV |  | [360 Panorama Synthesis from a Sparse Set of Images with Unknown Field of View](https://arxiv.org/abs/1904.03326) |  |  |
| 2021 | AAAI | SIG-SS | [Spherical Image Generation from a Single Image by Considering Scene Symmetry](https://ojs.aaai.org/index.php/AAAI/article/view/16242) |  | [![GitHub](https://img.shields.io/github/stars/hara012/sig-ss)](https://github.com/hara012/sig-ss) |
| 2021 | CVPR | EnvMapNet | [HDR Environment Map Estimation for Real-Time Augmented Reality](https://arxiv.org/abs/2011.10687) | [![link](https://img.shields.io/badge/Website-9cf)](https://machinelearning.apple.com/research/hdr-environment-map-estimation) | [![GitHub](https://img.shields.io/github/stars/apple/ml-envmapnet)](https://github.com/apple/ml-envmapnet) |
| 2021 | ICCV | Sat2vid | [Sat2vid: Street-view panoramic video synthesis from a single satellite image](https://arxiv.org/abs/2012.06628) |  |  |
| 2022 | 3DV | ImmerseGAN | [Guided Co-Modulated GAN for 360° Field of View Extrapolation](https://arxiv.org/abs/2204.07286) | [![link](https://img.shields.io/badge/Website-9cf)](https://lvsn.github.io/ImmerseGAN/) |  |
| 2022 | CVPR | OmniDreamer | [Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://arxiv.org/abs/2203.14668) | [![link](https://img.shields.io/badge/Website-9cf)](https://akmtn.github.io/omni-dreamer/) | [![GitHub](https://img.shields.io/github/stars/akmtn/OmniDreamer)](https://github.com/akmtn/OmniDreamer) |
| 2022 | ECCV | BIPS | [BIPS: Bi-modal Indoor Panorama Synthesis via Residual Depth-aided Adversarial Learning](https://arxiv.org/abs/2112.06179) |  | [![GitHub](https://img.shields.io/github/stars/chang9711/BIPS)](https://github.com/chang9711/BIPS) |
| 2022 | SIGGRAPH Asia | Text2Light | [Text2Light: Zero-Shot Text-Driven HDR Panorama Generation](https://arxiv.org/abs/2209.09898) | [![link](https://img.shields.io/badge/Website-9cf)](https://frozenburning.github.io/projects/text2light/) | [![GitHub](https://img.shields.io/github/stars/FrozenBurning/Text2Light)](https://github.com/FrozenBurning/Text2Light) |
| 2022 | TMM | PanoGAN | [Cross-View Panorama Image Synthesis](https://arxiv.org/abs/2203.11832) |  | [![GitHub](https://img.shields.io/github/stars/sswuai/PanoGAN)](https://github.com/sswuai/PanoGAN) |
| 2022 | TPAMI | Sat2Str | [Geometry-Guided Street-View Panorama Synthesis from Satellite Imagery](https://arxiv.org/abs/2103.01623) |  | [![GitHub](https://img.shields.io/github/stars/YujiaoShi/Sat2StrPanoramaSynthesis)](https://github.com/YujiaoShi/Sat2StrPanoramaSynthesis) |
| 2023 | CVPR | DiffCollage | [DiffCollage: Parallel Generation of Large Content with Diffusion Models](https://arxiv.org/abs/2303.17076) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/dir/diffcollage/) |  |
| 2023 | ICCV | Sat2Density | [Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs](https://arxiv.org/abs/2303.14672) | [![link](https://img.shields.io/badge/Website-9cf)](https://sat2density.github.io/) | [![GitHub](https://img.shields.io/github/stars/qianmingduowan/Sat2Density)](https://github.com/qianmingduowan/Sat2Density) |
| 2023 | MM | PanoDiff | [360-Degree Panorama Generation from Few Unregistered NFoV Images](https://arxiv.org/abs/2308.14686) |  | [![GitHub](https://img.shields.io/github/stars/shanemankiw/Panodiff)](https://github.com/shanemankiw/Panodiff) |
| 2023 | NeurIPS | MVDiffusion | [MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion](https://arxiv.org/abs/2307.01097) | [![link](https://img.shields.io/badge/Website-9cf)](https://mvdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/Tangshitao/MVDiffusion)](https://github.com/Tangshitao/MVDiffusion) |
| 2023 | TPAMI |  | [Spherical Image Generation From a Few Normal-Field-of-View Images by Considering Scene Symmetry](https://doi.org/10.1109/TPAMI.2022.3215933) |  | [![GitHub](https://img.shields.io/github/stars/hara012/sig-ss)](https://github.com/hara012/sig-ss) |
| 2023 | arXiv | LDM3D | [LDM3D: Latent Diffusion Model for 3D](https://arxiv.org/abs/2305.10853) |  |  |
| 2023 | arXiv | Diffusion360 | [Diffusion360: Seamless 360 Degree Panoramic Image Generation based on Diffusion Models](https://arxiv.org/abs/2311.13141) |  | [![GitHub](https://img.shields.io/github/stars/ArcherFMY/SD-T2I-360PanoImage)](https://github.com/ArcherFMY/SD-T2I-360PanoImage) |
| 2024 | ICLR | PanoDiffusion | [PanoDiffusion: 360-degree Panorama Outpainting via Diffusion](https://arxiv.org/abs/2307.03177) | [![link](https://img.shields.io/badge/Website-9cf)](https://sm0kywu.github.io/panodiffusion/) | [![GitHub](https://img.shields.io/github/stars/PanoDiffusion/PanoDiffusion)](https://github.com/PanoDiffusion/PanoDiffusion) |
| 2024 | CVPR | ControlRoom3D | [ControlRoom3D 🤖Room Generation using Semantic Proxy Rooms](https://arxiv.org/abs/2312.05208) | [![link](https://img.shields.io/badge/Website-9cf)](https://jonasschult.github.io/ControlRoom3D/) |  |
| 2024 | CVPR | Sat2Scene | [Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion](https://arxiv.org/abs/2401.10786) |  | [![GitHub](https://img.shields.io/github/stars/lizuoyue/sat2scene)](https://github.com/lizuoyue/sat2scene) |
| 2024 | CVPR | PanFusion | [Taming stable diffusion for text to 360◦ panorama image generation](https://arxiv.org/abs/2404.07949) | [![link](https://img.shields.io/badge/Website-9cf)](https://chengzhag.github.io/publication/panfusion/) | [![GitHub](https://img.shields.io/github/stars/chengzhag/PanFusion)](https://github.com/chengzhag/PanFusion) |
| 2024 | ECCV | DreamScene360 | [DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting](https://arxiv.org/abs/2404.06903) | [![link](https://img.shields.io/badge/Website-9cf)](https://dreamscene360.github.io/) | [![GitHub](https://img.shields.io/github/stars/ShijieZhou-UCLA/DreamScene360)](https://github.com/ShijieZhou-UCLA/DreamScene360) |
| 2024 | ECCV |  | [Geospecific View Generation - Geometry-Context Aware High-resolution Ground View Inference from Satellite Views](https://arxiv.org/abs/2407.08061) | [![link](https://img.shields.io/badge/Website-9cf)](https://gdaosu.github.io/geocontext/) |  |
| 2024 | IJCAI | FastScene | [FastScene: Text-Driven Fast Indoor 3D Scene Generation via Panoramic Gaussian Splatting](https://arxiv.org/abs/2405.05768) |  | [![GitHub](https://img.shields.io/github/stars/Mr-Ma-yikun/FastScene)](https://github.com/Mr-Ma-yikun/FastScene) |
| 2024 | NeurIPS | DiffPano | [DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion](https://arxiv.org/abs/2410.24203) | [![link](https://img.shields.io/badge/Website-9cf)](https://zju3dv.github.io/DiffPano/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/DiffPano)](https://github.com/zju3dv/DiffPano) |
| 2024 | TPAMI | PERF | [PERF: Panoramic Neural Radiance Field from a Single Panorama](https://arxiv.org/abs/2310.16831) | [![link](https://img.shields.io/badge/Website-9cf)](https://perf-project.github.io/) | [![GitHub](https://img.shields.io/github/stars/perf-project/PeRF)](https://github.com/perf-project/PeRF) |
| 2024 | TVCG | Dream360 | [Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via Transformer-Based 360° Image Outpainting](https://arxiv.org/abs/2401.10564) |  |  |
| 2024 | WACV | StitchDiffusion | [Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models](https://arxiv.org/abs/2310.18840) | [![link](https://img.shields.io/badge/Website-9cf)](https://littlewhitesea.github.io/stitchdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/littlewhitesea/StitchDiffusion)](https://github.com/littlewhitesea/StitchDiffusion) |
| 2024 | arXiv | HoloDreamer | [HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions](https://arxiv.org/abs/2407.15187) | [![link](https://img.shields.io/badge/Website-9cf)](https://zhouhyocean.github.io/holodreamer/) | [![GitHub](https://img.shields.io/github/stars/zhouhyOcean/HoloDreamer)](https://github.com/zhouhyOcean/HoloDreamer) |
| 2024 | arXiv | SceneDreamer360 | [SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with Panoramic Gaussian Splatting](https://arxiv.org/abs/2408.13711) | [![link](https://img.shields.io/badge/Website-9cf)](https://scenedreamer360.github.io/) | [![GitHub](https://img.shields.io/github/stars/liwrui/SceneDreamer360)](https://github.com/liwrui/SceneDreamer360) |
| 2025 | ICLR | CubeDiff | [CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation](https://arxiv.org/abs/2501.17162) | [![link](https://img.shields.io/badge/Website-9cf)](https://cubediff.github.io/) |  |
| 2025 | SIGGRAPH | LayerPano3D | [LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation](https://arxiv.org/abs/2408.13252) | [![link](https://img.shields.io/badge/Website-9cf)](https://ys-imtech.github.io/projects/LayerPano3D/) | [![GitHub](https://img.shields.io/github/stars/3DTopia/LayerPano3D)](https://github.com/3DTopia/LayerPano3D) |
| 2025 | arXiv |  | [A Recipe for Generating 3D Worlds From a Single Image](https://arxiv.org/abs/2503.16611) | [![link](https://img.shields.io/badge/Website-9cf)](https://katjaschwarz.github.io/worlds/) |  |

### Iterative Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2019 | TOG |  | [3D Ken Burns Effect from a Single Image](https://arxiv.org/abs/1909.05483) | [![link](https://img.shields.io/badge/Website-9cf)](https://sniklaus.com/kenburns) | [![GitHub](https://img.shields.io/github/stars/sniklaus/3d-ken-burns)](https://github.com/sniklaus/3d-ken-burns) |
| 2020 | CVPR | SynSin | [SynSin: End-to-end view synthesis from a single image](https://arxiv.org/abs/1912.08804) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.robots.ox.ac.uk/~ow/synsin.html) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/synsin)](https://github.com/facebookresearch/synsin) |
| 2020 | CVPR | 3D Photo | [3D Photography Using Context-Aware Layered Depth Inpainting](https://arxiv.org/abs/2004.04727) | [![link](https://img.shields.io/badge/Website-9cf)](https://shihmengli.github.io/3D-Photo-Inpainting/) | [![GitHub](https://img.shields.io/github/stars/vt-vl-lab/3d-photo-inpainting)](https://github.com/vt-vl-lab/3d-photo-inpainting) |
| 2020 | CVPR |  | [Single-View View Synthesis with Multiplane Images](https://arxiv.org/abs/2004.11364) | [![link](https://img.shields.io/badge/Website-9cf)](https://single-view-mpi.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research)](https://github.com/google-research/google-research/tree/master/single_view_mpi) |
| 2020 | NeurIPS | GVS | [Generative View Synthesis: From Single-view Semantics to Novel-view Images](https://arxiv.org/abs/2008.09106) | [![link](https://img.shields.io/badge/Website-9cf)](https://gvsnet.github.io/) | [![GitHub](https://img.shields.io/github/stars/tedyhabtegebrial/gvsnet)](https://github.com/tedyhabtegebrial/gvsnet) |
| 2021 | ICCV | Worldsheet | [Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image](https://arxiv.org/abs/2012.09854) | [![link](https://img.shields.io/badge/Website-9cf)](https://worldsheet.github.io/) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/worldsheet)](https://github.com/facebookresearch/worldsheet) |
| 2021 | ICCV | InfiniteNature | [Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image](https://arxiv.org/abs/2012.09855) | [![link](https://img.shields.io/badge/Website-9cf)](https://infinite-nature.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research)](https://github.com/google-research/google-research/tree/master/infinite_nature) |
| 2021 | ICCV | GFVS | [Geometry-free view synthesis: Transformers and no 3d priors](https://arxiv.org/abs/2104.07652) | [![link](https://img.shields.io/badge/Website-9cf)](https://compvis.github.io/geometry-free-view-synthesis/) | [![GitHub](https://img.shields.io/github/stars/CompVis/geometry-free-view-synthesis)](https://github.com/CompVis/geometry-free-view-synthesis) |
| 2021 | ICCV | Pathdreamer | [Pathdreamer: A World Model for Indoor Navigation](https://arxiv.org/abs/2105.08756) | [![link](https://img.shields.io/badge/Website-9cf)](https://google-research.github.io/pathdreamer/) | [![GitHub](https://img.shields.io/github/stars/google-research/pathdreamer)](https://github.com/google-research/pathdreamer) |
| 2021 | ICCV | PixelSynth | [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892) | [![link](https://img.shields.io/badge/Website-9cf)](https://crockwell.github.io/pixelsynth/) | [![GitHub](https://img.shields.io/github/stars/crockwell/pixelsynth)](https://github.com/crockwell/pixelsynth) |
| 2022 | CVPR | LOTR | [Look outside the room: Synthesizing a consistent long-term 3d scene video from a single image](https://arxiv.org/abs/2203.09457) | [![link](https://img.shields.io/badge/Website-9cf)](https://xrenaa.github.io/look-outside-room/) | [![GitHub](https://img.shields.io/github/stars/xrenaa/Look-Outside-Room)](https://github.com/xrenaa/Look-Outside-Room) |
| 2022 | ECCV | InfiniteNature-Zero | [InfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images](https://arxiv.org/abs/2207.11148) | [![link](https://img.shields.io/badge/Website-9cf)](https://infinite-nature-zero.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research)](https://github.com/google-research/google-research/tree/master/infinite_nature_zero) |
| 2022 | NeurIPS | SGAM | [SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping](https://openreview.net/forum?id=17KCLTbRymw) | [![link](https://img.shields.io/badge/Website-9cf)](https://yshen47.github.io/sgam/) | [![GitHub](https://img.shields.io/github/stars/yshen47/SGAM_NeurIPS22)](https://github.com/yshen47/SGAM_NeurIPS22) |
| 2023 | AAAI | SE3DS | [Simple and Effective Synthesis of Indoor 3D Scenes](https://arxiv.org/abs/2204.02960) |  | [![GitHub](https://img.shields.io/github/stars/google-research/se3ds)](https://github.com/google-research/se3ds) |
| 2023 | CVPR | 3D Cinemagraphy | [3D Cinemagraphy from a Single Image](https://arxiv.org/abs/2303.05724) | [![link](https://img.shields.io/badge/Website-9cf)](https://xingyi-li.github.io/3d-cinemagraphy/) | [![GitHub](https://img.shields.io/github/stars/xingyi-li/3d-cinemagraphy)](https://github.com/xingyi-li/3d-cinemagraphy) |
| 2023 | CVPR |  | [Consistent View Synthesis with Pose-Guided Diffusion Models](https://arxiv.org/abs/2303.17598) | [![link](https://img.shields.io/badge/Website-9cf)](https://poseguided-diffusion.github.io/) |  |
| 2023 | ICCV | DiffDreamer | [DiffDreamer: Towards Consistent Unsupervised Single-view Scene Extrapolation with Conditional Diffusion Models](https://arxiv.org/abs/2211.12131) | [![link](https://img.shields.io/badge/Website-9cf)](https://primecai.github.io/diffdreamer) | [![GitHub](https://img.shields.io/github/stars/primecai/DiffDreamer)](https://github.com/primecai/DiffDreamer) |
| 2023 | ICCV | Text2Room | [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/abs/2303.11989) | [![link](https://img.shields.io/badge/Website-9cf)](https://lukashoel.github.io/text-to-room/) | [![GitHub](https://img.shields.io/github/stars/lukasHoel/text2room)](https://github.com/lukasHoel/text2room) |
| 2023 | ICCV |  | [Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models](https://arxiv.org/abs/2304.10700) | [![link](https://img.shields.io/badge/Website-9cf)](https://yorkucvil.github.io/Photoconsistent-NVS/) | [![GitHub](https://img.shields.io/github/stars/YorkUCVIL/Photoconsistent-NVS)](https://github.com/YorkUCVIL/Photoconsistent-NVS) |
| 2023 | MM | Make-It-4D | [Make-It-4D: Synthesizing a Consistent Long-Term Dynamic Scene Video from a Single Image](https://arxiv.org/abs/2308.10257) |  | [![GitHub](https://img.shields.io/github/stars/leoShen917/Make-It-4D)](https://github.com/leoShen917/Make-It-4D) |
| 2023 | NeurIPS | SceneScape | [SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/abs/2302.01133) | [![link](https://img.shields.io/badge/Website-9cf)](https://scenescape.github.io/) | [![GitHub](https://img.shields.io/github/stars/RafailFridman/SceneScape)](https://github.com/RafailFridman/SceneScape) |
| 2023 | NeurIPS | PanoGen | [PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation](https://arxiv.org/abs/2305.19195) | [![link](https://img.shields.io/badge/Website-9cf)](https://pano-gen.github.io/) | [![GitHub](https://img.shields.io/github/stars/jialuli-luka/PanoGen)](https://github.com/jialuli-luka/PanoGen) |
| 2023 | arXiv | LucidDreamer | [LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes](https://arxiv.org/abs/2311.13384) | [![link](https://img.shields.io/badge/Website-9cf)](https://luciddreamer-cvlab.github.io/) | [![GitHub](https://img.shields.io/github/stars/luciddreamer-cvlab/LucidDreamer)](https://github.com/luciddreamer-cvlab/LucidDreamer) |
| 2023 | arXiv | Text2Immersion | [Text2Immersion: Generative Immersive Scene with 3D Gaussians](https://arxiv.org/abs/2312.09242) | [![link](https://img.shields.io/badge/Website-9cf)](https://ken-ouyang.github.io/text2immersion/index.html) |  |
| 2024 | AAAI | AOG-Net | [Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation](https://arxiv.org/abs/2309.03467) |  | [![GitHub](https://img.shields.io/github/stars/zhuqiangLu/AOG-NET-360)](https://github.com/zhuqiangLu/AOG-NET-360) |
| 2024 | CVPR | WonderJourney | [WonderJourney: Going from Anywhere to Everywhere](https://arxiv.org/abs/2312.03884) | [![link](https://img.shields.io/badge/Website-9cf)](https://kovenyu.com/wonderjourney/) | [![GitHub](https://img.shields.io/github/stars/KovenYu/WonderJourney)](https://github.com/KovenYu/WonderJourney) |
| 2024 | CVPR | 3D-SceneDreamer | [3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation](https://arxiv.org/abs/2403.09439) | [![link](https://img.shields.io/badge/Website-9cf)](https://microtreei.github.io/) |  |
| 2024 | ECCV | PanoFree | [PanoFree: Tuning-Free Holistic Multi-view Image Generation with Cross-view Self-Guidance](https://arxiv.org/abs/2408.02157) | [![link](https://img.shields.io/badge/Website-9cf)](https://panofree.github.io/) | [![GitHub](https://img.shields.io/github/stars/zxcvfd13502/PanoFree)](https://github.com/zxcvfd13502/PanoFree) |
| 2024 | MM | iControl3D | [iControl3D: An Interactive System for Controllable 3D Scene Generation](https://arxiv.org/abs/2408.01678) |  | [![GitHub](https://img.shields.io/github/stars/xingyi-li/iControl3D)](https://github.com/xingyi-li/iControl3D) |
| 2024 | NeurIPS | ODIN | [From an Image to a Scene: Learning to Imagine the World from a Million 360° Videos](https://arxiv.org/abs/2412.07770) | [![link](https://img.shields.io/badge/Website-9cf)](https://mattwallingford.github.io/ODIN/) | [![GitHub](https://img.shields.io/github/stars/MattWallingford/360-1M)](https://github.com/MattWallingford/360-1M) |
| 2024 | NeurIPS | CAT3D | [CAT3D: Create Anything in 3D with Multi-View Diffusion Models](https://arxiv.org/abs/2405.10314) | [![link](https://img.shields.io/badge/Website-9cf)](https://cat3d.github.io/) |  |
| 2024 | TVCG | Text2NeRF | [Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields](https://arxiv.org/abs/2305.11588) | [![link](https://img.shields.io/badge/Website-9cf)](https://eckertzhang.github.io/Text2NeRF.github.io/) | [![GitHub](https://img.shields.io/github/stars/eckertzhang/Text2NeRF)](https://github.com/eckertzhang/Text2NeRF) |
| 2024 | arXiv | OPa-Ma | [OPa-Ma: Text Guided Mamba for 360-degree Image Out-painting](https://arxiv.org/abs/2407.10923) |  | [![GitHub](https://img.shields.io/github/stars/PengleiGao/OPaMa)](https://github.com/PengleiGao/OPaMa) |
| 2024 | arXiv | Scene123 | [Scene123: One Prompt to 3D Scene Generation via Video-Assisted and Consistency-Enhanced MAE](https://arxiv.org/abs/2408.05477) | [![link](https://img.shields.io/badge/Website-9cf)](https://yiyingyang12.github.io/Scene123.github.io/) | [![GitHub](https://img.shields.io/github/stars/YiyingYang12/Scene123)](https://github.com/YiyingYang12/Scene123) |
| 2025 | 3DV | RealmDreamer | [RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion](https://arxiv.org/abs/2404.07199) | [![link](https://img.shields.io/badge/Website-9cf)](https://realmdreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/jaidevshriram/realmdreamer)](https://github.com/jaidevshriram/realmdreamer) |
| 2025 | 3DV | Invisible Stitch | [Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting](https://arxiv.org/abs/2404.19758) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.paulengstler.com/invisible-stitch/) | [![GitHub](https://img.shields.io/github/stars/paulengstler/invisible-stitch)](https://github.com/paulengstler/invisible-stitch) |
| 2025 | AAAI | BloomScene | [BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation](https://arxiv.org/abs/2501.10462) |  | [![GitHub](https://img.shields.io/github/stars/SparklingH/BloomScene)](https://github.com/SparklingH/BloomScene) |
| 2025 | CVPR | WonderWorld | [WonderWorld: Interactive 3D Scene Generation from a Single Image](https://arxiv.org/abs/2406.09394) | [![link](https://img.shields.io/badge/Website-9cf)](https://kovenyu.com/wonderworld/) | [![GitHub](https://img.shields.io/github/stars/KovenYu/WonderWorld)](https://github.com/KovenYu/WonderWorld) |
| 2025 | CVPR | ArtiScene | [ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary](https://arxiv.org/abs/2506.00742) | [![link](https://img.shields.io/badge/Website-9cf)](https://artiscene-cvpr.github.io/) | [![GitHub](https://img.shields.io/github/stars/jaclyngu/artiscene)](https://github.com/jaclyngu/artiscene) |
| 2025 | ICLR | 3D-MOM | [Optimizing 4D Gaussians for Dynamic Scene Video from Single Landscape Images](https://arxiv.org/abs/2504.05458) | [![link](https://img.shields.io/badge/Website-9cf)](https://paper.pnu-cvsp.com/ICLR2025_3D-MOM/) | [![GitHub](https://img.shields.io/github/stars/cvsp-lab/ICLR2025_3D-MOM)](https://github.com/cvsp-lab/ICLR2025_3D-MOM) |
| 2025 | arXiv | WonderTurbo | [WonderTurbo: Generating Interactive 3D World in 0.72 Seconds](https://arxiv.org/abs/2504.02261) | [![link](https://img.shields.io/badge/Website-9cf)](https://wonderturbo.github.io/) | [![GitHub](https://img.shields.io/github/stars/GigaAI-research/WonderTurbo)](https://github.com/GigaAI-research/WonderTurbo) |
| 2025 | arXiv | Bolt3D | [Bolt3D: Generating 3D Scenes in Seconds](https://arxiv.org/abs/2503.14445) | [![link](https://img.shields.io/badge/Website-9cf)](https://szymanowiczs.github.io/bolt3d) |  |
| 2025 | arXiv | SynCity | [SynCity: Training-Free Generation of 3D Worlds](https://arxiv.org/abs/2503.16420) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.paulengstler.com/syncity/) | [![GitHub](https://img.shields.io/github/stars/paulengstler/syncity)](https://github.com/paulengstler/syncity) |


## Video-based Generation

### Two-stage Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2024 | SIGGRAPH | Streetscapes | [Streetscapes Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion](https://arxiv.org/abs/2407.13759) | [![link](https://img.shields.io/badge/Website-9cf)](https://boyangdeng.com/streetscapes/) |  |
| 2024 | NeurIPS | 4Real | [4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models](https://arxiv.org/abs/2406.07472) | [![link](https://img.shields.io/badge/Website-9cf)](https://snap-research.github.io/4Real/) | [![GitHub](https://img.shields.io/github/stars/snap-research/4Real)](https://github.com/snap-research/4Real) |
| 2024 | arXiv | VividDream | [VividDream: Generating 3D Scene with Ambient Dynamics](https://arxiv.org/abs/2405.20334) |  |  |
| 2024 | arXiv | DimensionX | [DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion](https://arxiv.org/abs/2411.04928) | [![link](https://img.shields.io/badge/Website-9cf)](https://chenshuo20.github.io/DimensionX/) | [![GitHub](https://img.shields.io/github/stars/wenqsun/DimensionX)](https://github.com/wenqsun/DimensionX) |
| 2024 | arXiv | PaintScene4D | [PaintScene4D: Consistent 4D Scene Generation from Text Prompts](https://arxiv.org/abs/2412.04471) | [![link](https://img.shields.io/badge/Website-9cf)](https://paintscene4d.github.io/) | [![GitHub](https://img.shields.io/github/stars/paintscene4d/paintscene4d.github.io)](https://github.com/paintscene4d/paintscene4d.github.io) |
| 2025 | ICLR | GenXD | [GenXD: Generating Any 3D and 4D Scenes](https://arxiv.org/abs/2411.02319) | [![link](https://img.shields.io/badge/Website-9cf)](https://gen-x-d.github.io/) | [![GitHub](https://img.shields.io/github/stars/HeliosZhao/GenXD)](https://github.com/HeliosZhao/GenXD) |
| 2025 | CVPR | StarGen | [StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation](https://arxiv.org/abs/2501.05763) | [![link](https://img.shields.io/badge/Website-9cf)](https://zju3dv.github.io/StarGen/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/StarGen)](https://github.com/zju3dv/StarGen) |
| 2025 | arXiv | Free4D | [Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency](https://arxiv.org/abs/2503.20785) | [![link](https://img.shields.io/badge/Website-9cf)](https://free4d.github.io/) | [![GitHub](https://img.shields.io/github/stars/TQTQliu/Free4D)](https://github.com/TQTQliu/Free4D) |

### One-stage Generation

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2023 | arXiv | GAIA-1 | [GAIA-1: A Generative World Model for Autonomous Driving](https://arxiv.org/abs/2309.17080) | [![link](https://img.shields.io/badge/Website-9cf)](https://anthonyhu.github.io/gaia1) |  |
| 2023 | arXiv | ADriver-I | [ADriver-I: A General World Model for Autonomous Driving](https://arxiv.org/abs/2311.13549) |  |  |
| 2024 | ICLR | MagicDrive | [MagicDrive: Street View Generation with Diverse 3D Geometry Control](https://arxiv.org/abs/2310.02601) | [![link](https://img.shields.io/badge/Website-9cf)](https://gaoruiyuan.com/magicdrive/) | [![GitHub](https://img.shields.io/github/stars/cure-lab/MagicDrive)](https://github.com/cure-lab/MagicDrive) |
| 2024 | CVPR | Panacea | [Panacea: Panoramic and Controllable Video Generation for Autonomous Driving](https://arxiv.org/abs/2311.16813) | [![link](https://img.shields.io/badge/Website-9cf)](https://panacea-ad.github.io/) | [![GitHub](https://img.shields.io/github/stars/wenyuqing/panacea)](https://github.com/wenyuqing/panacea) |
| 2024 | CVPR | Drive-WM | [Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving](https://arxiv.org/abs/2311.17918) | [![link](https://img.shields.io/badge/Website-9cf)](https://drive-wm.github.io/) | [![GitHub](https://img.shields.io/github/stars/BraveGroup/Drive-WM)](https://github.com/BraveGroup/Drive-WM) |
| 2024 | CVPR | 360DVD | [360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model](https://arxiv.org/abs/2401.06578) | [![link](https://img.shields.io/badge/Website-9cf)](https://akaneqwq.github.io/360DVD/) | [![GitHub](https://img.shields.io/github/stars/Akaneqwq/360DVD)](https://github.com/Akaneqwq/360DVD) |
| 2024 | ECCV | DriveDreamer | [DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving](https://arxiv.org/abs/2309.09777) | [![link](https://img.shields.io/badge/Website-9cf)](https://drivedreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/JeffWang987/DriveDreamer)](https://github.com/JeffWang987/DriveDreamer) |
| 2024 | ECCV | DrivingDiffusion | [DrivingDiffusion: Layout-Guided Multi-View Driving Scenarios Video Generation with Latent Diffusion Model](https://arxiv.org/abs/2310.07771) | [![link](https://img.shields.io/badge/Website-9cf)](https://drivingdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/shalfun/DrivingDiffusion)](https://github.com/shalfun/DrivingDiffusion) |
| 2024 | ECCV | WoVoGen | [WoVoGen: World Volume-Aware Diffusion for Controllable Multi-camera Driving Scene Generation](https://arxiv.org/abs/2312.02934) |  | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/WoVoGen)](https://github.com/fudan-zvg/WoVoGen) |
| 2024 | NeurIPS | Vista | [Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability](https://arxiv.org/abs/2405.17398) | [![link](https://img.shields.io/badge/Website-9cf)](https://opendrivelab.com/Vista/) | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/Vista)](https://github.com/OpenDriveLab/Vista) |
| 2024 | arXiv | DIAMOND | [Diffusion for World Modeling: Visual Details Matter in Atari](https://arxiv.org/abs/2405.12399) | [![link](https://img.shields.io/badge/Website-9cf)](https://diamond-wm.github.io/) | [![GitHub](https://img.shields.io/github/stars/eloialonso/diamond)](https://github.com/eloialonso/diamond) |
| 2024 | arXiv | MagicDrive3D | [MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes](https://arxiv.org/abs/2405.14475) | [![link](https://img.shields.io/badge/Website-9cf)](https://gaoruiyuan.com/magicdrive3d/) | [![GitHub](https://img.shields.io/github/stars/flymin/MagicDrive3D)](https://github.com/flymin/MagicDrive3D) |
| 2024 | arXiv | Delphi | [Unleashing Generalization of End-to-End Autonomous Driving with Controllable Long Video Generation](https://arxiv.org/abs/2406.01349) | [![link](https://img.shields.io/badge/Website-9cf)](https://westlake-autolab.github.io/delphi.github.io/) | [![GitHub](https://img.shields.io/github/stars/westlake-autolab/Delphi)](https://github.com/westlake-autolab/Delphi) |
| 2024 | arXiv | BEVWorld | [BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space](https://arxiv.org/abs/2407.05679) |  | [![GitHub](https://img.shields.io/github/stars/zympsyche/BevWorld)](https://github.com/zympsyche/BevWorld) |
| 2024 | arXiv | DriveArena | [DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving](https://arxiv.org/abs/2408.00415) | [![link](https://img.shields.io/badge/Website-9cf)](https://pjlab-adg.github.io/DriveArena/) | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/DriveArena)](https://github.com/PJLab-ADG/DriveArena) |
| 2024 | arXiv | DiVE | [DiVE: DiT-based Video Generation with Enhanced Control](https://arxiv.org/abs/2409.01595) | [![link](https://img.shields.io/badge/Website-9cf)](https://liautoad.github.io/DIVE/) | [![GitHub](https://img.shields.io/github/stars/LiAutoAD/DIVE)](https://github.com/LiAutoAD/DIVE) |
| 2024 | arXiv | DreamForge | [DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes](https://arxiv.org/abs/2409.04003v3) | [![link](https://img.shields.io/badge/Website-9cf)](https://pjlab-adg.github.io/DriveArena/dreamforge/) |  |
| 2024 | arXiv | SyntheOcc | [SyntheOcc: Synthesize Geometric-Controlled Street View Images through 3D Semantic MPIs](https://arxiv.org/abs/2410.00337v1) | [![link](https://img.shields.io/badge/Website-9cf)](https://len-li.github.io/syntheocc-web/) | [![GitHub](https://img.shields.io/github/stars/EnVision-Research/SyntheOcc)](https://github.com/EnVision-Research/SyntheOcc) |
| 2024 | arXiv | MagicDrive-V2 | [MagicDrive-V2: High-Resolution Long Video Generation for Autonomous Driving with Adaptive Control](https://arxiv.org/abs/2411.13807v3) | [![link](https://img.shields.io/badge/Website-9cf)](https://gaoruiyuan.com/magicdrivedit/) | [![GitHub](https://img.shields.io/github/stars/flymin/MagicDriveDiT)](https://github.com/flymin/MagicDriveDiT) |
| 2024 | arXiv | HoloDrive | [HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving](https://arxiv.org/abs/2412.01407) |  |  |
| 2024 | arXiv | CogDriving | [Seeing Beyond Views: Multi-View Driving Scene Video Generation with Holistic Attention](https://arxiv.org/abs/2412.03520) | [![link](https://img.shields.io/badge/Website-9cf)](https://luhannan.github.io/CogDrivingPage/) |  |
| 2024 | arXiv | Imagine360 | [Imagine360: Immersive 360 Video Generation from Perspective Anchor](https://arxiv.org/abs/2412.03552) | [![link](https://img.shields.io/badge/Website-9cf)](https://ys-imtech.github.io/projects/Imagine360/) | [![GitHub](https://img.shields.io/github/stars/YS-IMTech/Imagine360)](https://github.com/YS-IMTech/Imagine360) |
| 2024 | arXiv | InfiniCube | [InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models](https://arxiv.org/abs/2412.03934) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/infinicube/) |  |
| 2024 | arXiv | DrivingWorld | [DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT](https://arxiv.org/abs/2412.19505) | [![link](https://img.shields.io/badge/Website-9cf)](https://huxiaotaostasy.github.io/DrivingWorld/) | [![GitHub](https://img.shields.io/github/stars/YvanYin/DrivingWorld)](https://github.com/YvanYin/DrivingWorld) |
| 2024 | arXiv | ViewCrafter | [ViewCrafter: Taming Video Diffusion Models for High-fidelity Novel View Synthesis](https://arxiv.org/abs/2409.02048) | [![link](https://img.shields.io/badge/Website-9cf)](https://drexubery.github.io/ViewCrafter/) | [![GitHub](https://img.shields.io/github/stars/Drexubery/ViewCrafter?style=social)](https://github.com/Drexubery/ViewCrafter) |
| 2024 | arXiv | ViewExtrapolator | [Novel View Extrapolation with Video Diffusion Priors](https://arxiv.org/abs/2411.14208) | [![link](https://img.shields.io/badge/Website-9cf)](https://kunhao-liu.github.io/ViewExtrapolator/) | [![GitHub](https://img.shields.io/github/stars/Kunhao-Liu/ViewExtrapolator?style=social)](https://github.com/Kunhao-Liu/ViewExtrapolator) |
| 2025 | AAAI | DriveDreamer-2 | [DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation](https://arxiv.org/abs/2403.06845) | [![link](https://img.shields.io/badge/Website-9cf)](https://drivedreamer2.github.io/) | [![GitHub](https://img.shields.io/github/stars/f1yfisher/DriveDreamer2)](https://github.com/f1yfisher/DriveDreamer2) |
| 2025 | ICLR | 4K4DGen | [4K4DGen: Panoramic 4D Generation at 4K Resolution](https://arxiv.org/abs/2406.13527) | [![link](https://img.shields.io/badge/Website-9cf)](https://4k4dgen.github.io/) |  |
| 2025 | ICLR | GameGen-X | [GameGen-X: Interactive Open-world Game Video Generation](https://arxiv.org/abs/2411.00769v3) | [![link](https://img.shields.io/badge/Website-9cf)](https://gamegen-x.github.io/) | [![GitHub](https://img.shields.io/github/stars/GameGen-X/GameGen-X)](https://github.com/GameGen-X/GameGen-X) |
| 2025 | ICLR | GameNGen | [Diffusion Models Are Real-Time Game Engines](https://arxiv.org/abs/2408.14837) | [![link](https://img.shields.io/badge/Website-9cf)](https://gamengen.github.io/) |  |
| 2025 | ICLR | Genex | [Generative World Explorer](https://arxiv.org/abs/2411.11844) | [![link](https://img.shields.io/badge/Website-9cf)](https://generative-world-explorer.github.io/) | [![GitHub](https://img.shields.io/github/stars/Beckschen/genEx)](https://github.com/Beckschen/genEx) |
| 2025 | ICLR | GLAD | [Glad: A Streaming Scene Generator for Autonomous Driving](https://arxiv.org/abs/2503.00045) |  |  |
| 2025 | CVPR | DrivingSphere | [DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation](https://arxiv.org/abs/2411.11252) | [![link](https://img.shields.io/badge/Website-9cf)](https://yanty123.github.io/DrivingSphere/) | [![GitHub](https://img.shields.io/github/stars/yanty123/DrivingSphere)](https://github.com/yanty123/DrivingSphere) |
| 2025 | CVPR | StreetCrafter | [StreetCrafter: Street View Synthesiswith Controllable Video Diffusion Models](https://arxiv.org/abs/2412.13188) | [![link](https://img.shields.io/badge/Website-9cf)](https://zju3dv.github.io/street_crafter/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/street_crafter)](https://github.com/zju3dv/street_crafter) |
| 2025 | CVPR | DriveScape | [DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation](https://arxiv.org/abs/2409.05463) | [![link](https://img.shields.io/badge/Website-9cf)](https://metadrivescape.github.io/papers_project/drivescapev1/index.html) |  |
| 2025 | CVPR | UniScene | [UniScene: Unified Occupancy-centric Driving Scene Generation](https://arxiv.org/abs/2412.05435) | [![link](https://img.shields.io/badge/Website-9cf)](https://arlo0o.github.io/uniscene/) | [![GitHub](https://img.shields.io/github/stars/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation)](https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation) |
| 2025 | CVPR | GEM | [GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control](https://arxiv.org/abs/2412.11198) | [![link](https://img.shields.io/badge/Website-9cf)](https://vita-epfl.github.io/GEM.github.io/) | [![GitHub](https://img.shields.io/github/stars/vita-epfl/GEM)](https://github.com/vita-epfl/GEM) |
| 2025 | CVPR | UMGen | [Generating Multimodal Driving Scenes via Next-Scene Prediction](https://arxiv.org/abs/2503.14945) | [![link](https://img.shields.io/badge/Website-9cf)](https://yanhaowu.github.io/UMGen/) | [![GitHub](https://img.shields.io/github/stars/YanhaoWu/UMGen)](https://github.com/YanhaoWu/UMGen) |
| 2025 | CVPR | CAT4D | [CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models](https://arxiv.org/abs/2411.18613) | [![link](https://img.shields.io/badge/Website-9cf)](https://cat-4d.github.io/) |  |
| 2025 | CVPR | Wonderland | [Wonderland: Navigating 3D Scenes from a Single Image](https://arxiv.org/abs/2412.12091) | [![link](https://img.shields.io/badge/Website-9cf)](https://snap-research.github.io/wonderland/) | [![GitHub](https://img.shields.io/github/stars/snap-research/wonderland)](https://github.com/snap-research/wonderland/) |
| 2025 | CVPR | VideoScene | [VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step](https://arxiv.org/abs/2504.01956) | [![link](https://img.shields.io/badge/Website-9cf)](https://hanyang-21.github.io/VideoScene/) | [![GitHub](https://img.shields.io/github/stars/hanyang-21/VideoScene?style=social)](https://github.com/hanyang-21/VideoScene) |
| 2025 | CVPR | Scene Splatter | [Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model](https://arxiv.org/abs/2504.02764) | [![link](https://img.shields.io/badge/Website-9cf)](https://shengjun-zhang.github.io/SceneSplatter/) |  |
| 2025 | CVPR | DynamicScaler | [DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes](https://arxiv.org/abs/2412.11100) | [![link](https://img.shields.io/badge/Website-9cf)](https://dynamic-scaler.pages.dev/) |  |
| 2025 | ICML | AdaWorld | [AdaWorld: Learning Adaptable World Models with Latent Actions](https://arxiv.org/abs/2503.18938) | [![link](https://img.shields.io/badge/Website-9cf)](https://adaptable-world-model.github.io/) | [![GitHub](https://img.shields.io/github/stars/Little-Podi/AdaWorld)](https://github.com/Little-Podi/AdaWorld) |
| 2025 | Nature | WHAM | [World and Human Action Models towards gameplay ideation](https://www.nature.com/articles/s41586-025-08600-3) | [![link](https://img.shields.io/badge/Website-9cf)](https://huggingface.co/microsoft/wham) |  |
| 2025 | arXiv | DreamDrive | [DreamDrive: Generative 4D Scene Modeling from Street View Images](https://arxiv.org/abs/2501.00601) | [![link](https://img.shields.io/badge/Website-9cf)](https://pointscoder.github.io/DreamDrive/) |  |
| 2025 | arXiv | MaskGWM | [MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction](https://arxiv.org/abs/2502.11663) | [![link](https://img.shields.io/badge/Website-9cf)](https://sensetime-fvg.github.io/MaskGWM/) | [![GitHub](https://img.shields.io/github/stars/SenseTime-FVG/OpenDWM)](https://github.com/SenseTime-FVG/OpenDWM) |
| 2025 | arXiv | UniFuture | [Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception](https://arxiv.org/abs/2503.13587) | [![link](https://img.shields.io/badge/Website-9cf)](https://dk-liang.github.io/UniFuture/) | [![GitHub](https://img.shields.io/github/stars/dk-liang/UniFuture)](https://github.com/dk-liang/UniFuture) |
| 2025 | arXiv | DiST-4D | [DiST-4D: Disentangled Spatiotemporal Diffusion with Metric Depth for 4D Driving Scene Generation](https://arxiv.org/abs/2503.15208) | [![link](https://img.shields.io/badge/Website-9cf)](https://royalmelon0505.github.io/DiST-4D/) | [![GitHub](https://img.shields.io/github/stars/royalmelon0505/dist4d)](https://github.com/royalmelon0505/dist4d) |
| 2025 | arXiv | GAIA-2 | [GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving](https://arxiv.org/abs/2503.20523) | [![link](https://img.shields.io/badge/Website-9cf)](https://wayve.ai/thinking/gaia-2/) |  |
| 2025 | arXiv | SteerX | [SteerX: Creating Any Camera-Free 3D and 4D Scenes with Geometric Steering](https://arxiv.org/abs/2503.12024) | [![link](https://img.shields.io/badge/Website-9cf)](https://byeongjun-park.github.io/SteerX/) | [![GitHub](https://img.shields.io/github/stars/byeongjun-park/SteerX)](https://github.com/byeongjun-park/SteerX) |
| 2025 | arXiv | WonderVerse | [WonderVerse: Extendable 3D Scene Generation with Video Generative Models](https://arxiv.org/abs/2503.09160) |  |  |
| 2025 | arXiv | FlexWorld | [FlexWorld: Progressively Expanding 3D Scenes for Flexiable-View Synthesis](https://arxiv.org/abs/2503.13265) | [![link](https://img.shields.io/badge/Website-9cf)](https://ml-gsai.github.io/FlexWorld/) | [![GitHub](https://img.shields.io/github/stars/ML-GSAI/FlexWorld?style=social)](https://github.com/ML-GSAI/FlexWorld) |
| 2025 | arXiv | GaussVideoDreamer | [GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting](https://arxiv.org/abs/2504.10001) |  |  |
| 2025 | arXiv | WORLDMEM | [WORLDMEM: Long-term Consistent World Simulation with Memory](https://arxiv.org/abs/2504.12369) | [![link](https://img.shields.io/badge/Website-9cf)](https://xizaoqu.github.io/worldmem/) | [![GitHub](https://img.shields.io/github/stars/xizaoqu/WorldMem?style=social)](https://github.com/xizaoqu/WorldMem) |
| 2025 | arXiv | HoloTime | [HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation](https://arxiv.org/abs/2504.21650) | [![link](https://img.shields.io/badge/Website-9cf)](https://zhouhyocean.github.io/holotime/) | [![GitHub](https://img.shields.io/github/stars/PKU-YuanGroup/HoloTime)](https://github.com/PKU-YuanGroup/HoloTime) |
| 2025 | arXiv | MineWorld | [MineWorld: a Real-Time and Open-Source Interactive World Model on Minecraft](https://arxiv.org/abs/2504.08388) |  | [![GitHub](https://img.shields.io/github/stars/microsoft/MineWorld)](https://github.com/microsoft/MineWorld) |
| 2025 | arXiv | GameFactory | [GameFactory: Creating New Games with Generative Interactive Videos](https://arxiv.org/abs/2501.08325) | [![link](https://img.shields.io/badge/Website-9cf)](https://yujiwen.github.io/gamefactory/) | [![GitHub](https://img.shields.io/github/stars/KwaiVGI/GameFactory)](https://github.com/KwaiVGI/GameFactory) |
| 2025 | arXiv | Matrix-Game | [Matrix-Game: Interactive World Foundation Model](https://github.com/SkyworkAI/Matrix-Game/raw/main/assets/report.pdf) | [![link](https://img.shields.io/badge/Website-9cf)](https://matrix-game-homepage.github.io/) | [![GitHub](https://img.shields.io/github/stars/SkyworkAI/Matrix-Game)](https://github.com/SkyworkAI/Matrix-Game) |
| 2025 | arXiv | CoGen | [CoGen: 3D Consistent Video Generation via Adaptive Conditioning for Autonomous Driving](https://arxiv.org/abs/2503.22231) | [![link](https://img.shields.io/badge/Website-9cf)](https://xiaomi-research.github.io/cogen/) |  |
| 2025 | arXiv | WonderPlay | [WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions](https://arxiv.org/abs/2505.18151) | [![link](https://img.shields.io/badge/Website-9cf)](https://kyleleey.github.io/WonderPlay/) |  |


# Datasets

## Indoor Datasets

| Year | Type  | Source  | Acronym | Paper   | Project     |
|------|-------|---------|---------|---------|-------------|
| 2012 | Indoor, Nature | Real | SUN360 | [Recognizing scene viewpoint using panoramic place representation](https://doi.org/10.1109/CVPR.2012.6247991) | [![link](https://img.shields.io/badge/Website-9cf)](https://vision.cs.princeton.edu/projects/2012/SUN360/data/) |
| 2012 | Indoor | Real | NYUv2 | [Indoor Segmentation and Support Inference From RGBD Images](https://doi.org//10.1007/978-3-642-33715-4_54) | [![link](https://img.shields.io/badge/Website-9cf)](https://cs.nyu.edu/~fergus/datasets/nyu_depth_v2.html) |
| 2015 | Indoor | Real | SunRGBD | [Sun RGB-D: A RGB-D scene understanding benchmark suite](https://doi.org/10.1109/CVPR.2015.7298655) | [![link](https://img.shields.io/badge/Website-9cf)](https://rgbd.cs.princeton.edu/) |
| 2016 | Indoor | Real | SceneNN | [SceneNN: A Scene Meshes Dataset with aNNotations](https://doi.org/10.1109/3DV.2016.18) | [![link](https://img.shields.io/badge/Website-9cf)](https://hkust-vgd.github.io/scenenn/) |
| 2017 | Indoor | Real | 2D-3D-S | [Joint 2D-3D-Semantic Data for Indoor Scene Understanding](https://arxiv.org/abs/1702.01105) | [![link](https://img.shields.io/badge/Website-9cf)](https://github.com/alexsax/2D-3D-Semantics) |
| 2017 | Indoor | Real | Matterport3D | [Matterport3D: Learning from RGB-D Data in Indoor Environments](https://arxiv.org/abs/1709.06158) | [![link](https://img.shields.io/badge/Website-9cf)](https://niessner.github.io/Matterport/) |
| 2017 | Indoor | Real | ScanNet | [ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes](https://arxiv.org/abs/1702.04405) | [![link](https://img.shields.io/badge/Website-9cf)](http://www.scan-net.org/) |
| 2017 | Indoor | Real | Laval Indoor | [Learning to Predict Indoor Illumination from a Single Image](https://arxiv.org/abs/1704.00090) | [![link](https://img.shields.io/badge/Website-9cf)](http://hdrdb.com/indoor/) |
| 2018 | Indoor, Urban | Real | RealEstate10K | [Stereo Magnification: Learning View Synthesis using Multiplane Images](https://arxiv.org/abs/1805.09817) | [![link](https://img.shields.io/badge/Website-9cf)](https://google.github.io/realestate10k/) |
| 2019 | Indoor | Real | Replica | [The Replica Dataset: A Digital Replica of Indoor Spaces](https://arxiv.org/abs/1906.05797) | [![link](https://img.shields.io/badge/Website-9cf)](https://github.com/facebookresearch/Replica-Dataset) |
| 2020 | Indoor | Real | 3DSSG | [Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions](https://arxiv.org/abs/2004.03967) | [![link](https://img.shields.io/badge/Website-9cf)](https://3dssg.github.io/) |
| 2021 | Indoor | Real | HM3D | [Habitat-Matterport 3D Dataset (HM3D): 1000 Large-scale 3D Environments for Embodied AI](https://arxiv.org/abs/2109.08238) | [![link](https://img.shields.io/badge/Website-9cf)](https://aihabitat.org/datasets/hm3d/) |
| 2023 | Indoor | Real | ScanNet++ | [ScanNet++: A high-fidelity dataset of 3D indoor scenes](https://arxiv.org/abs/2308.11417) | [![link](https://img.shields.io/badge/Website-9cf)](https://kaldir.vc.in.tum.de/scannetpp/) |
| 2023 | Indoor, Nature, Urban | Real | DL3DV-10K | [DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision](https://arxiv.org/abs/2312.16256) | [![link](https://img.shields.io/badge/Website-9cf)](https://dl3dv-10k.github.io/DL3DV-10K/) |
| 2012 | Indoor | Synthetic | SceneSynth | [Example-based synthesis of 3D object arrangements](https://doi.org/10.1145/2366145.2366154) | [![link](https://img.shields.io/badge/Website-9cf)](https://graphics.stanford.edu/projects/scenesynth/) |
| 2017 | Indoor | Synthetic | SUNCG | [Semantic Scene Completion from a Single Depth Image](https://arxiv.org/abs/1611.08974) | [![link](https://img.shields.io/badge/Website-9cf)](https://sscnet.cs.princeton.edu/) |
| 2020 | Indoor | Synthetic | Structured3D | [Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling](https://arxiv.org/abs/1908.00222) | [![link](https://img.shields.io/badge/Website-9cf)](https://structured3d-dataset.org/) |
| 2020 | Indoor | Synthetic | HyperSim | [HyperSim: A photorealistic synthetic dataset for holistic indoor scene understanding](https://arxiv.org/abs/2011.02523) | [![link](https://img.shields.io/badge/Website-9cf)](https://github.com/apple/ml-hypersim) |
| 2021 | Indoor | Synthetic | 3D-FRONT | [3D-FRONT: 3D Furnished Rooms with layOuts and semaNTics](https://arxiv.org/abs/2011.09127) | [![link](https://img.shields.io/badge/Website-9cf)](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset) |
| 2021 | Indoor | Synthetic | 3D-Future | [3D-FUTURE: 3D Furniture shape with TextURE](https://arxiv.org/abs/2009.09633) | [![link](https://img.shields.io/badge/Website-9cf)](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future) |
| 2023 | Indoor | Synthetic | SG-FRONT | [CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph Diffusion](https://arxiv.org/abs/2305.16283) | [![link](https://img.shields.io/badge/Website-9cf)](https://sites.google.com/view/commonscenes/dataset) |

## Natural Datasets

| Year | Type  | Source  | Acronym | Paper   | Project     |
|------|-------|---------|---------|---------|-------------|
| 2017 | Nature | Real | Laval  Outdoor | [Deep Sky Modeling for Single Image Outdoor Lighting Estimation](https://arxiv.org/abs/1905.03897) | [![link](https://img.shields.io/badge/Website-9cf)](http://hdrdb.com/outdoor/) |
| 2019 | Nature | Real | LHQ | [Aligning latent and image spaces to connect the unconnectable](https://arxiv.org/abs/2104.06954) | [![link](https://img.shields.io/badge/Website-9cf)](https://skor.sh/alis) |
| 2021 | Nature | Real | ACID | [Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image](https://arxiv.org/abs/2012.09855) | [![link](https://img.shields.io/badge/Website-9cf)](https://infinite-nature.github.io/) |

## Urban Datasets

| Year | Type  | Source  | Acronym | Paper   | Project     |
|------|-------|---------|---------|---------|-------------|
| 2012 | Urban | Real | KITTI | [Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite](https://doi.org/10.1109/CVPR.2012.6248074) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.cvlibs.net/datasets/kitti/) |
| 2016 | Urban | Real | Cityscapes | [The Cityscapes dataset for semantic urban scene understanding](https://arxiv.org/abs/1604.01685) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.cityscapes-dataset.com/) |
| 2019 | Urban | Real | SemanticKITTI | [SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences](https://arxiv.org/abs/1904.01416) | [![link](https://img.shields.io/badge/Website-9cf)](https://semantic-kitti.org/) |
| 2020 | Urban | Real | Waymo | [Scalability in Perception for Autonomous Driving: Waymo Open Dataset](https://arxiv.org/abs/1912.04838) | [![link](https://img.shields.io/badge/Website-9cf)](https://waymo.com/open/) |
| 2020 | Urban | Real | nuScenes | [nuScenes: A multimodal dataset for autonomous driving](https://arxiv.org/abs/1903.11027) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.nuscenes.org/) |
| 2023 | Urban | Real | KITTI-360 | [KITTI-360: A novel dataset and benchmarks for urban scene understanding in 2D and 3D.](https://arxiv.org/abs/2109.13410) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.cvlibs.net/datasets/kitti-360/) |
| 2020 | Urban | Real | HoliCity | [HoliCity: A city-scale data platform for learning holistic 3D structures](https://arxiv.org/abs/2008.03286) | [![link](https://img.shields.io/badge/Website-9cf)](https://holicity.io/) |
| 2022 | Urban | Real | OmniCity | [OmniCity: Omnipotent City Understanding with Multi-level and Multi-view Images](https://arxiv.org/abs/2208.00928) | [![link](https://img.shields.io/badge/Website-9cf)](https://city-super.github.io/omnicity/) |
| 2024 | Urban | Real | OSM | [CityDreamer: Compositional Generative Model of Unbounded 3D Cities](https://arxiv.org/abs/2309.00610) | [![link](https://img.shields.io/badge/Website-9cf)](https://gateway.infinitescript.com/s/OSM) |
| 2024 | Urban | Real | GoogleEarth | [CityDreamer: Compositional Generative Model of Unbounded 3D Cities](https://arxiv.org/abs/2309.00610) | [![link](https://img.shields.io/badge/Website-9cf)](https://gateway.infinitescript.com/s/GoogleEarth) |
| 2017 | Urban | Synthetic | CARLA | [CARLA: An Open Urban Driving Simulator](https://arxiv.org/abs/1711.03938) | [![link](https://img.shields.io/badge/Website-9cf)](https://carla.org/) |
| 2022 | Urban | Synthetic | CarlaSC | [MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments](https://arxiv.org/abs/2203.07060) | [![link](https://img.shields.io/badge/Website-9cf)](https://umich-curly.github.io/CarlaSC.github.io/) |
| 2020 | Urban | Synthetic | Virtual-KITTI-2 | [Virtual KITTI 2](https://arxiv.org/abs/2001.10773) | [![link](https://img.shields.io/badge/Website-9cf)](https://europe.naverlabs.com/research/proxy-virtual-worlds/) |
| 2025 | Urban | Synthetic | CityTopia | [CityDreamer4D: Compositional Generative Model of Unbounded 4D Cities](https://arxiv.org/abs/2501.08983) | [![link](https://img.shields.io/badge/Website-9cf)](https://haozhexie.com/project/city-dreamer-4d) |

# Applications and Tasks

## 3D Scene Editing

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2022 | CVPR | StyleMesh | [StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions](https://arxiv.org/abs/2112.01530) | [![link](https://img.shields.io/badge/Website-9cf)](https://lukashoel.github.io/stylemesh/) | [![GitHub](https://img.shields.io/github/stars/lukasHoel/stylemesh)](https://github.com/lukasHoel/stylemesh) |
| 2023 | CVPR | DisCoScene | [DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis](https://arxiv.org/abs/2212.11984) | [![link](https://img.shields.io/badge/Website-9cf)](https://snap-research.github.io/discoscene/) | [![GitHub](https://img.shields.io/github/stars/snap-research/discoscene)](https://github.com/snap-research/discoscene) |
| 2023 | CVPR | LEGO-Net | [LEGO-Net: Learning Regular Rearrangements of Objects in Rooms](https://arxiv.org/abs/2301.09629) | [![link](https://img.shields.io/badge/Website-9cf)](https://ivl.cs.brown.edu/research/lego-net.html) | [![GitHub](https://img.shields.io/github/stars/QiuhongAnnaWei/LEGO-Net)](https://github.com/QiuhongAnnaWei/LEGO-Net) |
| 2023 | CVPR | Lift3D | [Lift3D: Synthesize 3D Training Data by Lifting 2D GAN to 3D Generative Radiance Field](https://arxiv.org/abs/2304.03526) | [![link](https://img.shields.io/badge/Website-9cf)](https://len-li.github.io/lift3d-web/) | [![GitHub](https://img.shields.io/github/stars/EnVision-Research/Lift3D)](https://github.com/EnVision-Research/Lift3D) |
| 2023 | CVPR | Text2Scene | [Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details](https://arxiv.org/abs/2308.16880) |  |  |
| 2023 | ICRA | CabiNet | [CabiNet: Scaling Neural Collision Detection for Object Rearrangement with Procedural Scene Generation](https://arxiv.org/abs/2304.09302) | [![link](https://img.shields.io/badge/Website-9cf)](https://cabinet-object-rearrangement.github.io/) | [![GitHub](https://img.shields.io/github/stars/NVlabs/cabi_net)](https://github.com/NVlabs/cabi_net) |
| 2023 | MM | RoomDreamer | [RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent Geometry and Texture](https://arxiv.org/abs/2305.11337) |  |  |
| 2024 | CVPR | SceneTex | [SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors](https://arxiv.org/abs/2311.17261) | [![link](https://img.shields.io/badge/Website-9cf)](https://daveredrum.github.io/SceneTex/) | [![GitHub](https://img.shields.io/github/stars/daveredrum/SceneTex)](https://github.com/daveredrum/SceneTex) |
| 2024 | CVPR | ControlRoom3D | [ControlRoom3D 🤖Room Generation using Semantic Proxy Rooms](https://arxiv.org/abs/2312.05208) | [![link](https://img.shields.io/badge/Website-9cf)](https://jonasschult.github.io/ControlRoom3D/) |  |
| 2024 | ECCV | StyleCity | [StyleCity: Large-Scale 3D Urban Scenes Stylization](https://arxiv.org/abs/2404.10681) | [![link](https://img.shields.io/badge/Website-9cf)](https://www.chenyingshu.com/stylecity3d/) | [![GitHub](https://img.shields.io/github/stars/chenyingshu/stylecity3d)](https://github.com/chenyingshu/stylecity3d) |
| 2024 | ECCV | RoomTex | [RoomTex: Texturing Compositional Indoor Scenes via Iterative Inpainting](https://arxiv.org/abs/2406.02461) | [![link](https://img.shields.io/badge/Website-9cf)](https://qwang666.github.io/RoomTex/) | [![GitHub](https://img.shields.io/github/stars/qwang666/RoomTex-)](https://github.com/qwang666/RoomTex-) |
| 2024 | ECCV | 3D-GOI | [3D-GOI: 3D GAN Omni-Inversion for Multifaceted and Multi-object Editing](https://arxiv.org/abs/2311.12050) | [![link](https://img.shields.io/badge/Website-9cf)](https://3d-goi.github.io/) |  |
| 2024 | MM | SceneExpander | [SceneExpander: Real-Time Scene Synthesis for Interactive Floor Plan Editing](https://openreview.net/forum?id=V5HU1OvHnx) |  | [![GitHub](https://img.shields.io/github/stars/Shao-Kui/3DScenePlatform?tab=readme-ov-file#sceneexpander)](https://github.com/Shao-Kui/3DScenePlatform?tab=readme-ov-file#sceneexpander) |
| 2024 | NeurIPS | Neural Assets | [Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models](https://arxiv.org/abs/2406.09292) | [![link](https://img.shields.io/badge/Website-9cf)](https://neural-assets.github.io/) |  |
| 2024 | NeurIPS | DeBaRA | [DeBaRA: Denoising-Based 3D Room Arrangement Generation](https://arxiv.org/abs/2409.18336) |  |  |
| 2024 | SIGGRAPH Asia | InstanceTex | [InstanceTex: Instance-level Controllable Texture Synthesis for 3D Scenes via Diffusion Priors](https://doi.org/10.1145/3680528.3687633) | [![link](https://img.shields.io/badge/Website-9cf)](https://vcc.tech/research/2024/InstanceTex) |  |
| 2024 | TVCG | SceneDirector | [SceneDirector: Interactive Scene Synthesis by Simultaneously Editing Multiple Objects in Real-Time](https://doi.org/10.1109/TVCG.2023.3268115) |  | [![GitHub](https://img.shields.io/github/stars/Shao-Kui/3DScenePlatform#scenedirector)](https://github.com/Shao-Kui/3DScenePlatform#scenedirector) |
| 2024 | VR | DreamSpace | [DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture Propagation](https://arxiv.org/abs/2310.13119) | [![link](https://img.shields.io/badge/Website-9cf)](https://ybbbbt.com/publication/dreamspace/) | [![GitHub](https://img.shields.io/github/stars/ybbbbt/dreamspace)](https://github.com/ybbbbt/dreamspace) |
| 2025 | 3DV | Ctrl-Room | [Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints](https://arxiv.org/abs/2310.03602) | [![link](https://img.shields.io/badge/Website-9cf)](https://fangchuan.github.io/ctrl-room.github.io/) | [![GitHub](https://img.shields.io/github/stars/fangchuan/Ctrl-Room)](https://github.com/fangchuan/Ctrl-Room) |
| 2025 | CVPR | RoomPainter | [RoomPainter: View-Integrated Diffusion for Consistent Indoor Scene Texturing](https://arxiv.org/abs/2412.16778) |  |  |

## Human-Scene Interaction

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2022 | CVPR |  | [Towards Diverse and Natural Scene-aware 3D Human Motion Synthesis](https://arxiv.org/abs/2205.13001) |  |  |
| 2022 | ECCV | COINS | [Compositional Human-Scene Interaction Synthesis with Semantic Control](https://arxiv.org/abs/2207.12824) | [![link](https://img.shields.io/badge/Website-9cf)](https://zkf1997.github.io/COINS/index.html) | [![GitHub](https://img.shields.io/github/stars/zkf1997/COINS)](https://github.com/zkf1997/COINS) |
| 2023 | CVPR | SceneDiffuser | [Diffusion-based Generation, Optimization, and Planning in 3D Scenes](https://arxiv.org/abs/2301.06015) | [![link](https://img.shields.io/badge/Website-9cf)](https://scenediffuser.github.io/) | [![GitHub](https://img.shields.io/github/stars/scenediffuser/Scene-Diffuser)](https://github.com/scenediffuser/Scene-Diffuser) |
| 2023 | ICCV | DIMOS | [Synthesizing Diverse Human Motions in 3D Indoor Scenes](https://arxiv.org/abs/2305.12411) | [![link](https://img.shields.io/badge/Website-9cf)](https://zkf1997.github.io/DIMOS/) | [![GitHub](https://img.shields.io/github/stars/zkf1997/DIMOS)](https://github.com/zkf1997/DIMOS) |
| 2023 | SIGGRAPH | InterPhys | [Synthesizing Physical Character-Scene Interactions](https://arxiv.org/abs/2302.00883) | [![link](https://img.shields.io/badge/Website-9cf)](https://xbpeng.github.io/projects/InterPhys/index.html) |  |
| 2024 | 3DV | InterScene | [Synthesizing Physically Plausible Human Motions in 3D Scenes](https://arxiv.org/abs/2308.09036) | [![link](https://img.shields.io/badge/Website-9cf)](https://liangpan99.github.io/InterScene/) | [![GitHub](https://img.shields.io/github/stars/liangpan99/InterScene)](https://github.com/liangpan99/InterScene) |
| 2024 | CVPR | GenZI | [GenZI: Zero-Shot 3D Human-Scene Interaction Generation](https://arxiv.org/abs/2311.17737) | [![link](https://img.shields.io/badge/Website-9cf)](https://craigleili.github.io/projects/genzi/) |  |
| 2024 | ICLR | UniHSI | [UniHSI: Unified Human-Scene Interaction via Prompted Chain-of-Contacts](https://arxiv.org/abs/2309.07918) | [![link](https://img.shields.io/badge/Website-9cf)](https://xizaoqu.github.io/unihsi/) | [![GitHub](https://img.shields.io/github/stars/OpenRobotLab/UniHSI)](https://github.com/OpenRobotLab/UniHSI) |
| 2024 | arXiv | SIMS | [SIMS: Simulating Stylized Human-Scene Interactions with Retrieval-Augmented Script Generation](https://arxiv.org/abs/2411.19921) | [![link](https://img.shields.io/badge/Website-9cf)](https://wenjiawang0312.github.io/projects/sims/) | [![GitHub](https://img.shields.io/github/stars/WenjiaWang0312/sims-stylized_hsi)](https://github.com/WenjiaWang0312/sims-stylized_hsi) |
| 2025 | CVPR | TokenHSI | [TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization](https://arxiv.org/abs/2503.19901) | [![link](https://img.shields.io/badge/Website-9cf)](https://liangpan99.github.io/TokenHSI/) | [![GitHub](https://img.shields.io/github/stars/liangpan99/TokenHSI)](https://github.com/liangpan99/TokenHSI) |


## Embodied AI

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2022 | NeurIPS | ProcTHOR | [ProcTHOR: Large-Scale Embodied AI Using Procedural Generation](https://arxiv.org/abs/2206.06994) | [![link](https://img.shields.io/badge/Website-9cf)](https://procthor.allenai.org/) | [![GitHub](https://img.shields.io/github/stars/allenai/procthor)](https://github.com/allenai/procthor) |
| 2024 | CVPR | Holodeck | [Holodeck: Language Guided Generation of 3D Embodied AI Environments](https://arxiv.org/abs/2312.09067) | [![link](https://img.shields.io/badge/Website-9cf)](https://yueyang1996.github.io/holodeck/) | [![GitHub](https://img.shields.io/github/stars/allenai/Holodeck)](https://github.com/allenai/Holodeck) |
| 2024 | CVPR | PhyScene | [PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI](https://arxiv.org/abs/2404.09465) | [![link](https://img.shields.io/badge/Website-9cf)](https://physcene.github.io/) | [![GitHub](https://img.shields.io/github/stars/PhyScene/PhyScene)](https://github.com/PhyScene/PhyScene) |
| 2024 | NeurIPS | Architect | [Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting](https://arxiv.org/abs/2411.09823) | [![link](https://img.shields.io/badge/Website-9cf)](https://wangyian-me.github.io/Architect/) | [![GitHub](https://img.shields.io/github/stars/wangyian-me/architect_official_code)](https://github.com/wangyian-me/architect_official_code) |
| 2024 | arXiv | GRUtopia | [GRUtopia: Dream General Robots in a City at Scale](https://arxiv.org/abs/2407.10943) | [![link](https://img.shields.io/badge/Website-9cf)](https://grutopia.github.io/) | [![GitHub](https://img.shields.io/github/stars/OpenRobotLab/GRUtopia)](https://github.com/OpenRobotLab/GRUtopia) |
| 2024 | arXiv | EmbodiedCity | [EmbodiedCity: A Benchmark Platform for Embodied Agent in Real-world City Environment](https://arxiv.org/abs/2410.09604) | [![link](https://img.shields.io/badge/Website-9cf)](https://embodied-city.fiblab.net/) | [![GitHub](https://img.shields.io/github/stars/tsinghua-fib-lab/EmbodiedCity)](https://github.com/tsinghua-fib-lab/EmbodiedCity) |
| 2024 | arXiv | InfiniteWorld | [InfiniteWorld: A Unified Scalable Simulation Framework for General Visual-Language Robot Interaction](https://arxiv.org/abs/2412.05789) |  | [![GitHub](https://img.shields.io/github/stars/pzhren/InfiniteWorld)](https://github.com/pzhren/InfiniteWorld) |
| 2025 | ICLR | MetaUrban | [MetaUrban: An Embodied AI Simulation Platform for Urban Micromobility](https://arxiv.org/abs/2407.08725) | [![link](https://img.shields.io/badge/Website-9cf)](https://metadriverse.github.io/metaurban/) | [![GitHub](https://img.shields.io/github/stars/metadriverse/metaurban)](https://github.com/metadriverse/metaurban) |

## Robotics

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2023 | NeurIPS | UniPi | [Learning Universal Policies via Text-Guided Video Generation](https://arxiv.org/abs/2302.00111) | [![link](https://img.shields.io/badge/Website-9cf)](https://universal-policy.github.io/unipi/) |  |
| 2023 | NeurIPS | HiP | [Compositional Foundation Models for Hierarchical Planning](https://arxiv.org/abs/2309.08587) | [![link](https://img.shields.io/badge/Website-9cf)](https://hierarchical-planning-foundation-model.github.io/) | [![GitHub](https://img.shields.io/github/stars/anuragajay/hip)](https://github.com/anuragajay/hip) |
| 2024 | CoRL | Imagination Policy | [Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies](https://arxiv.org/abs/2406.11740) | [![link](https://img.shields.io/badge/Website-9cf)](https://haojhuang.github.io/imagine_page/) | [![GitHub](https://img.shields.io/github/stars/HaojHuang/imagination-policy-cor24)](https://github.com/HaojHuang/imagination-policy-cor24) |
| 2024 | CoRL | Eurekaverse | [Eurekaverse: Environment Curriculum Generation via Large Language Models](https://arxiv.org/abs/2411.01775) | [![link](https://img.shields.io/badge/Website-9cf)](https://eureka-research.github.io/eurekaverse/) | [![GitHub](https://img.shields.io/github/stars/eureka-research/eurekaverse)](https://github.com/eureka-research/eurekaverse) |
| 2024 | ICLR | GR-1 | [Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation](https://arxiv.org/abs/2312.13139) | [![link](https://img.shields.io/badge/Website-9cf)](https://gr1-manipulation.github.io/) | [![GitHub](https://img.shields.io/github/stars/bytedance/GR-1)](https://github.com/bytedance/GR-1) |
| 2024 | ICML | RoboGen | [RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation](https://arxiv.org/abs/2311.01455) | [![link](https://img.shields.io/badge/Website-9cf)](https://robogen-ai.github.io/) | [![GitHub](https://img.shields.io/github/stars/Genesis-Embodied-AI/RoboGen)](https://github.com/Genesis-Embodied-AI/RoboGen) |
| 2024 | ICML | VLP | [Using Left and Right Brains Together: Towards Vision and Language Planning](https://arxiv.org/abs/2402.10534) |  |  |
| 2024 | IROS | ActNeRF | [Uncertainty-aware Active Learning of NeRF-based Object Models for Robot Manipulators using Visual and Re-orientation Actions](https://arxiv.org/abs/2404.01812) | [![link](https://img.shields.io/badge/Website-9cf)](https://actnerf.github.io/) | [![GitHub](https://img.shields.io/github/stars/ActNeRF/ActNeRF)](https://github.com/ActNeRF/ActNeRF) |
| 2024 | NeurIPS | CLOVER | [Closed-Loop Visuomotor Control with Generative Expectation for Robotic Manipulation](https://arxiv.org/abs/2409.09016) |  | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/CLOVER)](https://github.com/OpenDriveLab/CLOVER) |
| 2024 | arXiv | GR-2 | [GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation](https://arxiv.org/abs/2410.06158) | [![link](https://img.shields.io/badge/Website-9cf)](https://gr2-manipulation.github.io/) |  |
| 2025 | ICLR | SlowFast-VGen | [SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation](https://arxiv.org/abs/2410.23277) | [![link](https://img.shields.io/badge/Website-9cf)](https://slowfast-vgen.github.io/) | [![GitHub](https://img.shields.io/github/stars/slowfast-vgen/slowfast-vgen)](https://github.com/slowfast-vgen/slowfast-vgen) |
| 2025 | ICML | Video Prediction Policy | [Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations](https://arxiv.org/abs/2412.14803) | [![link](https://img.shields.io/badge/Website-9cf)](https://video-prediction-policy.github.io/) | [![GitHub](https://img.shields.io/github/stars/roboterax/video-prediction-policy)](https://github.com/roboterax/video-prediction-policy) |
| 2025 | arXiv | VideoWorld | [VideoWorld: Exploring Knowledge Learning from Unlabeled Videos](https://arxiv.org/abs/2501.09781) | [![link](https://img.shields.io/badge/Website-9cf)](https://maverickren.github.io/VideoWorld.github.io/) | [![GitHub](https://img.shields.io/github/stars/ByteDance-Seed/VideoWorld)](https://github.com/ByteDance-Seed/VideoWorld) |
| 2025 | arXiv | Cosmos-Transfer1 | [Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control](https://arxiv.org/abs/2503.14492) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/dir/cosmos-transfer1/) | [![GitHub](https://img.shields.io/github/stars/nvidia-cosmos/cosmos-transfer1)](https://github.com/nvidia-cosmos/cosmos-transfer1) |
| 2025 | arXiv | TesserAct | [TesserAct: Learning 4D Embodied World Models](https://arxiv.org/abs/2504.20995) | [![link](https://img.shields.io/badge/Website-9cf)](https://tesseractworld.github.io/) | [![GitHub](https://img.shields.io/github/stars/UMass-Embodied-AGI/TesserAct)](https://github.com/UMass-Embodied-AGI/TesserAct) |

## Autonomous Driving

| Year | Venue | Acronym | Paper | Project | Repo@GitHub |
|------|-------|---------|-------|---------|-------------|
| 2023 | arXiv | GAIA-1 | [GAIA-1: A Generative World Model for Autonomous Driving](https://arxiv.org/abs/2309.17080) | [![link](https://img.shields.io/badge/Website-9cf)](https://anthonyhu.github.io/gaia1) |  |
| 2023 | arXiv | Cam4DOcc | [Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications](https://arxiv.org/abs/2311.17663) |  | [![GitHub](https://img.shields.io/github/stars/haomo-ai/Cam4DOcc)](https://github.com/haomo-ai/Cam4DOcc) |
| 2024 | CVPR | Drive-WM | [Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving](https://arxiv.org/abs/2311.17918) | [![link](https://img.shields.io/badge/Website-9cf)](https://drive-wm.github.io/) | [![GitHub](https://img.shields.io/github/stars/BraveGroup/Drive-WM)](https://github.com/BraveGroup/Drive-WM) |
| 2024 | ECCV | DriveDreamer | [DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving](https://arxiv.org/abs/2309.09777) | [![link](https://img.shields.io/badge/Website-9cf)](https://drivedreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/JeffWang987/DriveDreamer)](https://github.com/JeffWang987/DriveDreamer) |
| 2024 | ECCV | OccWorld | [OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving](https://arxiv.org/abs/2311.16038) | [![link](https://img.shields.io/badge/Website-9cf)](https://wzzheng.net/OccWorld/) | [![GitHub](https://img.shields.io/github/stars/wzzheng/OccWorld)](https://github.com/wzzheng/OccWorld) |
| 2024 | ECCV | WoVoGen | [WoVoGen: World Volume-Aware Diffusion for Controllable Multi-camera Driving Scene Generation](https://arxiv.org/abs/2312.02934) |  | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/WoVoGen)](https://github.com/fudan-zvg/WoVoGen) |
| 2024 | ICLR | MagicDrive | [MagicDrive: Street View Generation with Diverse 3D Geometry Control](https://arxiv.org/abs/2310.02601) | [![link](https://img.shields.io/badge/Website-9cf)](https://gaoruiyuan.com/magicdrive/) | [![GitHub](https://img.shields.io/github/stars/cure-lab/MagicDrive)](https://github.com/cure-lab/MagicDrive) |
| 2024 | NeurIPS | Vista | [Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability](https://arxiv.org/abs/2405.17398) | [![link](https://img.shields.io/badge/Website-9cf)](https://opendrivelab.com/Vista/) | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/Vista)](https://github.com/OpenDriveLab/Vista) |
| 2024 | arXiv | OccSora | [OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving](https://arxiv.org/abs/2405.20337) | [![link](https://img.shields.io/badge/Website-9cf)](https://wzzheng.net/OccSora/) | [![GitHub](https://img.shields.io/github/stars/wzzheng/OccSora)](https://github.com/wzzheng/OccSora) |
| 2024 | arXiv | Delphi | [Unleashing Generalization of End-to-End Autonomous Driving with Controllable Long Video Generation](https://arxiv.org/abs/2406.01349) | [![link](https://img.shields.io/badge/Website-9cf)](https://westlake-autolab.github.io/delphi.github.io/) | [![GitHub](https://img.shields.io/github/stars/westlake-autolab/Delphi)](https://github.com/westlake-autolab/Delphi) |
| 2024 | arXiv | DriveArena | [DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving](https://arxiv.org/abs/2408.00415) | [![link](https://img.shields.io/badge/Website-9cf)](https://pjlab-adg.github.io/DriveArena/) | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/DriveArena)](https://github.com/PJLab-ADG/DriveArena) |
| 2024 | arXiv | DiVE | [DiVE: DiT-based Video Generation with Enhanced Control](https://arxiv.org/abs/2409.01595) | [![link](https://img.shields.io/badge/Website-9cf)](https://liautoad.github.io/DIVE/) | [![GitHub](https://img.shields.io/github/stars/LiAutoAD/DIVE)](https://github.com/LiAutoAD/DIVE) |
| 2024 | arXiv | DreamForge | [DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes](https://arxiv.org/abs/2409.04003) | [![link](https://img.shields.io/badge/Website-9cf)](https://pjlab-adg.github.io/DriveArena/dreamforge/) |  |
| 2024 | arXiv | DrivingWorld | [DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT](https://arxiv.org/abs/2412.19505) | [![link](https://img.shields.io/badge/Website-9cf)](https://huxiaotaostasy.github.io/DrivingWorld/) | [![GitHub](https://img.shields.io/github/stars/YvanYin/DrivingWorld)](https://github.com/YvanYin/DrivingWorld) |
| 2025 | AAAI | Drive-OccWorld | [Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving](https://arxiv.org/abs/2408.14197) | [![link](https://img.shields.io/badge/Website-9cf)](https://drive-occworld.github.io/) | [![GitHub](https://img.shields.io/github/stars/yuyang-cloud/Drive-OccWorld)](https://github.com/yuyang-cloud/Drive-OccWorld) |
| 2025 | CVPR | DrivingSphere | [DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation](https://arxiv.org/abs/2411.11252) | [![link](https://img.shields.io/badge/Website-9cf)](https://yanty123.github.io/DrivingSphere/) | [![GitHub](https://img.shields.io/github/stars/yanty123/DrivingSphere)](https://github.com/yanty123/DrivingSphere) |
| 2025 | ICLR | GLAD | [Glad: A Streaming Scene Generator for Autonomous Driving](https://arxiv.org/abs/2503.00045) |  |  |
| 2025 | arXiv | DreamDrive | [DreamDrive: Generative 4D Scene Modeling from Street View Images](https://arxiv.org/abs/2501.00601) | [![link](https://img.shields.io/badge/Website-9cf)](https://pointscoder.github.io/DreamDrive/) |  |
| 2025 | arXiv | Cosmos-Transfer1 | [Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control](https://arxiv.org/abs/2503.14492) | [![link](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/dir/cosmos-transfer1/) | [![GitHub](https://img.shields.io/github/stars/nvidia-cosmos/cosmos-transfer1)](https://github.com/nvidia-cosmos/cosmos-transfer1) |
