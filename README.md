
## Procedural Generation

### Rule-based Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 1988 | SIGGRAPH |  | [Terrain simulation using a model of stream erosion](https://dl.acm.org/doi/10.1145/378456.378519) |  |  |
| 1989 | SIGGRAPH |  | [The synthesis and rendering of eroded fractal terrains](https://dl.acm.org/doi/10.1145/74334.74337) |  |  |
| 1993 | Graphics Interface |  | [Fractal Model of Mountains with Rivers](https://www.algorithmicbotany.org/papers/mountains.gi93.pdf) | [Link](https://algorithmicbotany.org/papers/mountains.gi93.html) |  |
| 1998 | SIGGRAPH |  | [Realistic modeling and rendering of plant ecosystems](http://www.graphics.stanford.edu/papers/ecosys/ecosys.pdf) | [Link](http://www.graphics.stanford.edu/papers/ecosys/) |  |
| 2001 | SIGGRAPH | CityEngine | [Procedural modeling of cities](https://cgl.ethz.ch/Downloads/Publications/Papers/2001/p_Par01.pdf) |  |  |
| 2005 | VRST |  | [Modeling Landscapes with Ridges and Rivers](https://expreg.org/amsi/C/articles/fbelhadj_200511.pdf) |  |  |
| 2006 | TOG |  | [Procedural modeling of buildings](https://dl.acm.org/doi/10.1145/1141911.1141931) |  |  |
| 2007 | GDTW | Citygen | [Citygen: An Interactive System for Procedural City Generation](https://www.citygen.net/files/citygen_gdtw07.pdf) |  |  |
| 2007 | SI3D |  | [Example-based model synthesis](https://paulmerrell.org/model_synthesis.pdf) |  |  |
| 2007 | TVCG |  | [Terrain Synthesis from Digital Elevation Models](http://terrainsynthesis.org/) |  |  |
| 2008 | TOG |  | [Continuous model synthesis](https://paulmerrell.org/wp-content/uploads/2021/06/continuous.pdf) |  |  |
| 2009 | CGF |  | [Arches: a Framework for Modeling Complex Terrains](https://perso.liris.cnrs.fr/eric.galin/Articles/2009-arches.pdf) |  |  |
| 2009 | CGF |  | [Interactive Geometric Simulation of 4D Cities](https://peterwonka.net/Publications/pdfs/2009.EG.Weber.UrbanSimulation.FinalVersion.pdf) |  |  |
| 2009 | TOG |  | [Interactive design of urban spaces using geometrical and behavioral modeling](https://www.cs.purdue.edu/cgvlab/www/resources/papers/Vanegas-2009-Interactive_Design_of_Urban_Spaces_Using_Geometrical_and_Behavio.pdf) |  |  |
| 2011 | SI3D |  | [Urban Ecosystem Design](https://www.cs.purdue.edu/cgvlab/www/publications/Benes11I3D/) |  |  |
| 2011 | TOG |  | [Metropolis procedural modeling.](https://vladlen.info/publications/metropolis-procedural-modeling/) |  |  |
| 2012 | TOG |  | [Inverse design of urban procedural models](http://www.ignaciogarciadorado.com/p/2012_SIGA/2012_SIGA.html) |  |  |
| 2013 | TOG |  | [Terrain Generation Using Procedural Models Based on Hydrology](https://hal.science/hal-01339224) |  |  |
| 2015 | TOG | WorldBrush | [WorldBrush: Interactive Example-Based Synthesis of Procedural Virtual Worlds](https://www.cs.purdue.edu/cgvlab/www/publications/Emilien15ToG/) |  |  |
| 2016 | 3DV |  | [Proceduralization for Editing 3D Architectural Models](https://www.cs.purdue.edu/cgvlab/www/resources/papers/Demir-2016-Proceduralization_for_editing_3d_architectural_models.pdf) |  |  |
| 2016 | CGF |  | [Example-Driven Procedural Urban Roads](http://www.ignaciogarciadorado.com/p/2015_CGF/2015_CGF_ExampleRoads.pdf) |  |  |
| 2017 | TOG |  | [Authoring landscapes by combining ecosystem and terrain erosion simulation](https://dl.acm.org/doi/abs/10.1145/3072959.3073667) |  |  |
| 2019 | TOG |  | [Synthetic silviculture: multi-scale modeling of plant ecosystems](https://storage.googleapis.com/pirk.io/papers/Makowski.etal-2019-Synthetic-Silviculture.pdf) |  |  |
| 2021 | TOG |  | [Authoring Consistent Landscapes with Flora and Fauna](https://www-sop.inria.fr/reves/Basilic/2021/ECCMMBC21/Authoring_Consistent_Landscapes_with_Flora_and_Fauna.pdf) |  |  |
| 2022 | TOG | Ecoclimates | [Ecoclimates: Climate-Response Modeling of Vegetation](https://storage.googleapis.com/pirk.io/projects/ecoclimates/index.html) |  |  |
| 2023 | CVPR | Infinigen | [Infinite Photorealistic Worlds using Procedural Generation](https://arxiv.org/abs/2306.09310) | [Link](https://infinigen.org/) | [![GitHub](https://img.shields.io/github/stars/princeton-vl/infinigen?style=social)](https://github.com/princeton-vl/infinigen) |
| 2023 | TOG |  | [Forming Terrains by Glacial Erosion](https://dl.acm.org/doi/abs/10.1145/3592422) |  |  |
| 2023 | TOG |  | [Large-scale terrain authoring through interactive erosion simulation](https://hal.science/hal-04361019/document) |  |  |
| 2023 | TOG |  | [Authoring and Simulating Meandering Rivers](https://hal.science/hal-04227965) |  |  |

### Optimization-based Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2002 | Graphics Interface |  | [Constraint-based Automatic Placement for Scene Composition](https://graphicsinterface.org/wp-content/uploads/gi2002-4.pdf) | [Link](https://graphicsinterface.org/proceedings/gi2002/gi2002-4/) |  |
| 2010 | TOG |  | [Computer-Generated Residential Building Layouts](https://cs.stanford.edu/people/eschkufz/docs/siggraph_asia_10.pdf) |  |  |
| 2011 | SIGGRAPH |  | [Interactive Furniture Layout Using Interior Design Guidelines](http://graphics.berkeley.edu/papers/Merrell-IFL-2011-08/Merrell-IFL-2011-08.pdf) |  |  |
| 2011 | SIGGRAPH | Make it home | [Make it home: automatic optimization of furniture arrangement](https://web.cs.ucla.edu/~dt/papers/siggraph11/siggraph11.pdf) |  |  |
| 2012 | TOG |  | [Example-based synthesis of 3D object arrangements](https://graphics.stanford.edu/projects/scenesynth/) |  |  |
| 2015 | TVCG | Clutterpalette | [The Clutterpalette: An Interactive Tool for Detailing Indoor Scenes](https://craigyuyu.github.io/home/papers/clutterpalette_low_res.pdf) | [Link](https://craigyuyu.github.io/home/project_pages/clutterpalette/index.html) |  |
| 2018 | CGF |  | [MIQP-based Layout Design for Building Interiors](https://wutomwu.github.io/publications/2018-IPLayout/paper_low_res.pdf) | [Link](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13380) |  |
| 2018 | CVPR |  | [Human-centric Indoor Scene Synthesis Using Stochastic Grammar](https://arxiv.org/abs/1808.08473) |  | [![GitHub](https://img.shields.io/github/stars/SiyuanQi-zz/human-centric-scene-synthesis?style=social)](https://github.com/SiyuanQi-zz/human-centric-scene-synthesis) |
| 2018 | VR |  | [Automatic Furniture Arrangement Using Greedy Cost Minimization](https://peterkan.com/download/ieeevr2018.pdf) |  |  |
| 2021 | MM | MageAdd | [MageAdd: Real-Time Interaction Simulation for Scene Synthesis](https://cg.cs.tsinghua.edu.cn/course/vis/Shao-Kui/MageAdd.pdf) |  | [![GitHub](https://img.shields.io/github/stars/Shao-Kui/3DScenePlatform?tab=readme-ov-file#mageadd?style=social)](https://github.com/Shao-Kui/3DScenePlatform?tab=readme-ov-file#mageadd) |
| 2021 | TVCG |  | [Fast 3D Indoor Scene Synthesis by Learning Spatial Relation Priors of Objects](https://cg.cs.tsinghua.edu.cn/course/vis/Shao-Kui/fast3d.pdf) |  |  |
| 2021 | arXiv | LUMINOUS | [LUMINOUS: Indoor Scene Generation for Embodied AI Challenges](https://arxiv.org/abs/2111.05527) |  | [![GitHub](https://img.shields.io/github/stars/amazon-science/indoor-scene-generation-eai?style=social)](https://github.com/amazon-science/indoor-scene-generation-eai) |
| 2022 | NeurIPS | ProcTHOR | [ProcTHOR: Large-Scale Embodied AI Using Procedural Generation](https://arxiv.org/abs/2206.06994) | [Link](https://procthor.allenai.org/) | [![GitHub](https://img.shields.io/github/stars/allenai/procthor?style=social)](https://github.com/allenai/procthor) |
| 2024 | CVPR | Infinigen Indoors | [Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation](https://arxiv.org/abs/2406.11824) | [Link](https://infinigen.org/) | [![GitHub](https://img.shields.io/github/stars/princeton-vl/infinigen?style=social)](https://github.com/princeton-vl/infinigen) |

### LLM-based Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2023 | NeurIPS | LayoutGPT | [LayoutGPT: Compositional Visual Planning and Generation with Large Language Models](https://arxiv.org/abs/2305.15393) | [Link](https://layoutgpt.github.io/) | [![GitHub](https://img.shields.io/github/stars/weixi-feng/LayoutGPT?style=social)](https://github.com/weixi-feng/LayoutGPT) |
| 2023 | arXiv | 3D-GPT | [3D-GPT: Procedural 3D Modeling with Large Language Models](https://arxiv.org/abs/2310.12945) | [Link](https://chuny1.github.io/3DGPT/3dgpt.html) | [![GitHub](https://img.shields.io/github/stars/Chuny1/3DGPT?style=social)](https://github.com/Chuny1/3DGPT) |
| 2024 | CVPR | GraphDreamer | [GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs](https://arxiv.org/abs/2312.00093) | [Link](https://graphdreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/GGGHSL/GraphDreamer?style=social)](https://github.com/GGGHSL/GraphDreamer) |
| 2024 | ECCV | AnyHome | [AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes](https://arxiv.org/abs/2312.06644) | [Link](https://ivl.cs.brown.edu/research/anyhome) | [![GitHub](https://img.shields.io/github/stars/FreddieRao/anyhome_github?style=social)](https://github.com/FreddieRao/anyhome_github) |
| 2024 | ECCV | SceneTeller | [SceneTeller: Language-to-3D Scene Generation](https://arxiv.org/abs/2407.20727) | [Link](https://sceneteller.github.io/) | [![GitHub](https://img.shields.io/github/stars/sceneteller/SceneTeller?style=social)](https://github.com/sceneteller/SceneTeller) |
| 2024 | ICML | SceneCraft | [SceneCraft: An LLM Agent for Synthesizing 3D Scenes as Blender Code](https://arxiv.org/abs/2403.01248) |  |  |
| 2024 | MM |  | [Controllable Procedural Generation of Landscapes](https://dl.acm.org/doi/10.1145/3664647.3681129) |  | [![GitHub](https://img.shields.io/github/stars/omegafantasy/ControllableLandscape?style=social)](https://github.com/omegafantasy/ControllableLandscape) |
| 2024 | SIGGRAPH Asia | DIScene | [DIScene: Object Decoupling and Interaction Modeling for Complex Scene Generation](https://dl.acm.org/doi/pdf/10.1145/3680528.3687589) | [Link](https://dl.acm.org/doi/full/10.1145/3680528.3687589) |  |
| 2024 | arXiv |  | [Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases](https://arxiv.org/abs/2403.09675) |  |  |
| 2024 | arXiv | SceneX | [SceneX: Procedural Controllable Large-scale Scene Generation](https://arxiv.org/abs/2403.15698) | [Link](https://zhouzq1.github.io/SceneX/) | [![GitHub](https://img.shields.io/github/stars/zhouzq1/SceneX?style=social)](https://github.com/zhouzq1/SceneX) |
| 2024 | arXiv | I-Design | [I-Design: Personalized LLM Interior Designer](https://arxiv.org/abs/2404.02838) | [Link](https://atcelen.github.io/I-Design/) | [![GitHub](https://img.shields.io/github/stars/IDesign/?style=social)](https://github.com/atcelen/IDesign/) |
| 2024 | arXiv | LLplace | [LLplace: The 3D Indoor Scene Layout Generation and Editing via Large Language Model](https://arxiv.org/abs/2406.03866) |  |  |
| 2024 | arXiv | CityCraft | [CityCraft: A Real Crafter for 3D City Generation](https://arxiv.org/abs/2406.04983) |  | [![GitHub](https://img.shields.io/github/stars/djFatNerd/CityCraft?style=social)](https://github.com/djFatNerd/CityCraft) |
| 2024 | arXiv | CityX | [CityX: Controllable Procedural Content Generation for Unbounded 3D Cities](https://arxiv.org/abs/2407.17572) | [Link](https://cityx-lab.github.io/) | [![GitHub](https://img.shields.io/github/stars/cityx-lab/CityX-Lab?style=social)](https://github.com/cityx-lab/CityX-Lab) |
| 2024 | arXiv | GraphCanvas3D | [Graph Canvas for Controllable 3D Scene Generation](https://arxiv.org/abs/2412.00091) |  |  |
| 2024 | arXiv | LayoutVLM | [LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models](https://arxiv.org/abs/2412.02193) | [Link](https://ai.stanford.edu/~sunfanyun/layoutvlm/) | [![GitHub](https://img.shields.io/github/stars/sunfanyunn/LayoutVLM?style=social)](https://github.com/sunfanyunn/LayoutVLM) |
| 2024 | arXiv | Proc-GS | [Proc-GS Procedural Building Generation for City Assembly with 3D Gaussians](https://arxiv.org/abs/2412.07660) | [Link](https://city-super.github.io/procgs/) | [![GitHub](https://img.shields.io/github/stars/ProcGS/?style=social)](https://github.com/city-super/ProcGS/) |
| 2025 | CVPR |  | [Global-Local Tree Search in VLMs for 3D Indoor Scene Generation](https://arxiv.org/abs/2503.18476) |  | [![GitHub](https://img.shields.io/github/stars/dw-dengwei/TreeSearchGen?style=social)](https://github.com/dw-dengwei/TreeSearchGen) |
| 2025 | arXiv | WorldCraft | [WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents](https://arxiv.org/abs/2502.15601) |  |  |

## Neural-3D Generation

### Scene Parameters

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2018 | SIGGRAPH | DeepSynth | [Deep Convolutional Priors for Indoor Scene Synthesis](https://msavva.github.io/files/deepsynth.pdf) | [Link](https://dl.acm.org/doi/10.1145/3197517.3201362) | [![GitHub](https://img.shields.io/github/stars/brownvc/deep-synth?style=social)](https://github.com/brownvc/deep-synth) |
| 2019 | CVPR | FastSynth | [Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models](https://arxiv.org/abs/1811.12463) |  | [![GitHub](https://img.shields.io/github/stars/brownvc/fast-synth?style=social)](https://github.com/brownvc/fast-synth) |
| 2020 | SIGGRAPH |  | [Deep Generative Modeling for Scene Synthesis via Hybrid Representations](https://arxiv.org/abs/1808.02084) |  |  |
| 2021 | 3DV | SceneFormer | [SceneFormer: Indoor Scene Generation with Transformers](https://arxiv.org/abs/2012.09793) | [Link](https://xinpeng-wang.github.io/sceneformer/) | [![GitHub](https://img.shields.io/github/stars/cy94/sceneformer?style=social)](https://github.com/cy94/sceneformer) |
| 2021 | ICCV | Sync2Gen | [Scene Synthesis via Uncertainty-Driven Attribute Synchronization](https://arxiv.org/abs/2108.13499) |  | [![GitHub](https://img.shields.io/github/stars/yanghtr/Sync2Gen?style=social)](https://github.com/yanghtr/Sync2Gen) |
| 2021 | NeurIPS | ATISS | [ATISS: Autoregressive Transformers for Indoor Scene Synthesis](https://arxiv.org/abs/2110.03675) | [Link](https://research.nvidia.com/labs/toronto-ai/ATISS/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/atiss?style=social)](https://github.com/nv-tlabs/atiss) |
| 2022 | ECCV | Pose2Room | [Pose2Room: Understanding 3D Scenes from Human Activities](https://arxiv.org/abs/2112.03030) | [Link](https://yinyunie.github.io/pose2room-page/) | [![GitHub](https://img.shields.io/github/stars/yinyunie/pose2room?style=social)](https://github.com/yinyunie/pose2room) |
| 2022 | SIGGRAPH Asia | SUMMON | [Scene Synthesis from Human Motion](https://arxiv.org/abs/2301.01424) | [Link](https://lijiaman.github.io/projects/summon/) | [![GitHub](https://img.shields.io/github/stars/onestarYX/summon?style=social)](https://github.com/onestarYX/summon) |
| 2023 | CVPR |  | [Learning 3D Scene Priors with 2D Supervision](https://arxiv.org/abs/2211.14157) | [Link](https://yinyunie.github.io/sceneprior-page/) | [![GitHub](https://img.shields.io/github/stars/yinyunie/ScenePriors?style=social)](https://github.com/yinyunie/ScenePriors) |
| 2023 | CVPR | MIME | [MIME: Human-Aware 3D Scene Generation](https://arxiv.org/abs/2212.04360) | [Link](https://mime.is.tue.mpg.de/) | [![GitHub](https://img.shields.io/github/stars/yhw-yhw/MIME?style=social)](https://github.com/yhw-yhw/MIME) |
| 2023 | NeurIPS |  | [Language-driven Scene Synthesis using Multi-conditional Diffusion Model](https://arxiv.org/abs/2310.15948) | [Link](https://lang-scene-synth.github.io/) | [![GitHub](https://img.shields.io/github/stars/andvg3/LSDM?style=social)](https://github.com/andvg3/LSDM) |
| 2023 | arXiv | Ctrl-Room | [Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints](https://arxiv.org/abs/2310.03602) | [Link](https://fangchuan.github.io/ctrl-room.github.io/) | [![GitHub](https://img.shields.io/github/stars/fangchuan/Ctrl-Room?style=social)](https://github.com/fangchuan/Ctrl-Room) |
| 2024 | 3DV | RoomDesigner | [RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation](https://arxiv.org/abs/2310.10027) |  | [![GitHub](https://img.shields.io/github/stars/zhao-yiqun/RoomDesigner?style=social)](https://github.com/zhao-yiqun/RoomDesigner) |
| 2024 | CVPR | DiffuScene | [DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis](https://arxiv.org/abs/2303.14207) | [Link](https://tangjiapeng.github.io/projects/DiffuScene/) | [![GitHub](https://img.shields.io/github/stars/tangjiapeng/DiffuScene?style=social)](https://github.com/tangjiapeng/DiffuScene) |
| 2024 | CVPR | SceneWiz3D | [SceneWiz3D: Towards Text-guided 3D Scene Composition](https://arxiv.org/abs/2312.08885) | [Link](https://zqh0253.github.io/SceneWiz3D/) | [![GitHub](https://img.shields.io/github/stars/zqh0253/SceneWiz3D?style=social)](https://github.com/zqh0253/SceneWiz3D) |
| 2024 | CVPR | PhyScene | [PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI](https://arxiv.org/abs/2404.09465) | [Link](https://physcene.github.io/) | [![GitHub](https://img.shields.io/github/stars/PhyScene/PhyScene?style=social)](https://github.com/PhyScene/PhyScene) |
| 2024 | ECCV | DreamScene | [DreamScene: 3D Gaussian-Based Text-to-3D Scene Generation viaÂ Formation Pattern Sampling](https://arxiv.org/abs/2404.03575) | [Link](https://dreamscene-project.github.io/) | [![GitHub](https://img.shields.io/github/stars/DreamScene-Project/DreamScene?style=social)](https://github.com/DreamScene-Project/DreamScene) |
| 2024 | ICML | GALA3D | [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://arxiv.org/abs/2402.07207) | [Link](https://gala3d.github.io/) | [![GitHub](https://img.shields.io/github/stars/VDIGPKU/GALA3D?style=social)](https://github.com/VDIGPKU/GALA3D) |
| 2024 | ICML |  | [Disentangled 3D Scene Generation with Layout Learning](https://arxiv.org/abs/2402.16936) | [Link](https://dave.ml/layoutlearning/) |  |
| 2024 | MM | RelScene | [RelScene: A Benchmark and baseline for Spatial Relations in text-driven 3D Scene Generation](https://openreview.net/forum?id=GIw7pmMPPX) |  |  |
| 2024 | NeurIPS | DeBaRA | [DeBaRA: Denoising-Based 3D Room Arrangement Generation](https://arxiv.org/abs/2409.18336) |  |  |
| 2024 | SIGGRAPH | INFERACT | [Physics-based Scene Layout Generation From Human Motion](https://arxiv.org/abs/2405.12460) | [Link](https://jiann-li.github.io/physcenegen/) |  |
| 2024 | arXiv | Lay-A-Scene | [Lay-A-Scene: Personalized 3D Object Arrangement Using Text-to-Image Priors](https://arxiv.org/abs/2406.00687) | [Link](https://lay-a-scene.github.io/) | [![GitHub](https://img.shields.io/github/stars/ohad204/Lay-A-Scene?style=social)](https://github.com/ohad204/Lay-A-Scene) |
| 2025 | CVPR | SceneFactor | [SceneFactor: Factored Latent 3D Diffusion for Controllable 3D Scene Generation](https://arxiv.org/abs/2412.01801) | [Link](https://alexeybokhovkin.github.io/scenefactor/) | [![GitHub](https://img.shields.io/github/stars/alexeybokhovkin/SceneFactor?style=social)](https://github.com/alexeybokhovkin/SceneFactor) |

### Scene Graph

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2014 | EMNLP |  | [Learning Spatial Knowledge for Text to 3D Scene Generation](https://aclanthology.org/D14-1217/) |  |  |
| 2016 | CGF |  | [Learning 3D Scene Synthesis from Annotated RGB-D Images](https://www2.cs.sfu.ca/~haoz/pubs/zeinab_sgp16_scene.pdf) |  |  |
| 2017 | TOG |  | [Adaptive synthesis of indoor scenes via activity-associated object relation graphs]() |  |  |
| 2018 | TOG |  | [Language-Driven Synthesis of 3D Scenes from Scene Databases](https://dl.acm.org/doi/10.1145/3272127.3275035) | [Link](https://manyili12345.github.io/Publication/2018/T2S/index.html) |  |
| 2019 | ICCV | Meta-Sim | [Meta-Sim: Learning to Generate Synthetic Datasets](https://arxiv.org/abs/1904.11621) | [Link](https://research.nvidia.com/labs/toronto-ai/meta-sim/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/meta-sim?style=social)](https://github.com/nv-tlabs/meta-sim) |
| 2019 | SIGGRAPH | GRAINS | [GRAINS: Generative Recursive Autoencoders for INdoor Scenes](https://arxiv.org/abs/1807.09193) | [Link](https://manyili12345.github.io/Publication/2018/GRAINS/index.html) | [![GitHub](https://img.shields.io/github/stars/ManyiLi12345/GRAINS?style=social)](https://github.com/ManyiLi12345/GRAINS) |
| 2019 | SIGGRAPH | PlanIT | [PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks](https://dl.acm.org/doi/10.1145/3306346.3322941) |  | [![GitHub](https://img.shields.io/github/stars/brownvc/planit?style=social)](https://github.com/brownvc/planit) |
| 2020 | CVPR | 3D-SLN | [End-to-End Optimization of Scene Layout](https://arxiv.org/abs/2007.11744) | [Link](http://3dsln.csail.mit.edu/) | [![GitHub](https://img.shields.io/github/stars/aluo-x/3D_SLN?style=social)](https://github.com/aluo-x/3D_SLN) |
| 2020 | ECCV | Meta-Sim 2 | [Meta-Sim 2 Unsupervised Learning of Scene Structure for Synthetic Data Generation](https://arxiv.org/abs/2008.09092) | [Link](https://amlankar.github.io/publication/meta-sim2/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/meta-sim-structure?style=social)](https://github.com/nv-tlabs/meta-sim-structure) |
| 2021 | ICCV | Graph-to-3D | [Graph-to-3D: End-to-End Generation and Manipulation of 3D Scenes Using Scene Graphs](https://arxiv.org/abs/2108.08841) | [Link](https://he-dhamo.github.io/Graphto3D/) | [![GitHub](https://img.shields.io/github/stars/he-dhamo/graphto3d?style=social)](https://github.com/he-dhamo/graphto3d) |
| 2023 | NeurIPS | CommonScenes | [CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph Diffusion](https://arxiv.org/abs/2305.16283) | [Link](https://sites.google.com/view/commonscenes) | [![GitHub](https://img.shields.io/github/stars/ymxlzgy/commonscenes?style=social)](https://github.com/ymxlzgy/commonscenes) |
| 2023 | TPAMI | SceneHGN | [SceneHGN: Hierarchical Graph Networks for 3D Indoor Scene Generation With Fine-Grained Geometry](https://arxiv.org/abs/2302.10237) | [Link](http://geometrylearning.com/scenehgn/) | [![GitHub](https://img.shields.io/github/stars/tommaoer/SceneHGN?style=social)](https://github.com/tommaoer/SceneHGN) |
| 2024 | ECCV | SEK | [External Knowledge Enhanced 3D Scene Generation from Sketch](https://arxiv.org/abs/2403.14121) |  |  |
| 2024 | ECCV | EchoScene | [EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion](https://arxiv.org/abs/2405.00915) | [Link](https://sites.google.com/view/echoscene) | [![GitHub](https://img.shields.io/github/stars/ymxlzgy/echoscene?style=social)](https://github.com/ymxlzgy/echoscene) |
| 2024 | ICLR | InstructScene | [InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior](https://arxiv.org/abs/2402.04717) | [Link](https://chenguolin.github.io/projects/InstructScene/) | [![GitHub](https://img.shields.io/github/stars/chenguolin/InstructScene?style=social)](https://github.com/chenguolin/InstructScene) |
| 2025 | arXiv |  | [Controllable 3D Outdoor Scene Generation via Scene Graphs](https://arxiv.org/abs/2503.07152) |  | [![GitHub](https://img.shields.io/github/stars/yuhengliu02/control-3d-scene?style=social)](https://github.com/yuhengliu02/control-3d-scene) |

### Semantic Layout

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2021 | ICCV | GANcraft | [GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds](https://arxiv.org/abs/2104.07659) | [Link](https://nvlabs.github.io/GANcraft/) | [![GitHub](https://img.shields.io/github/stars/NVlabs/imaginaire?style=social)](https://github.com/NVlabs/imaginaire) |
| 2023 | CVPR | DisCoScene | [DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis](https://arxiv.org/abs/2212.11984) | [Link](https://snap-research.github.io/discoscene/) | [![GitHub](https://img.shields.io/github/stars/snap-research/discoscene?style=social)](https://github.com/snap-research/discoscene) |
| 2023 | ICCV | InfiniCity | [InfiniCity: Infinite-Scale City Synthesis](https://arxiv.org/abs/2301.09637) | [Link](https://hubert0527.github.io/infinicity/) |  |
| 2023 | ICCV | CC3D | [CC3D: Layout-Conditioned Generation of Compositional 3D Scenes](https://arxiv.org/abs/2303.12074) | [Link](https://sherwinbahmani.github.io/cc3d/) | [![GitHub](https://img.shields.io/github/stars/sherwinbahmani/cc3d?style=social)](https://github.com/sherwinbahmani/cc3d) |
| 2023 | ICCV | Set-the-Scene | [Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes](https://arxiv.org/abs/2303.13450) | [Link](https://danacohen95.github.io/Set-the-Scene/) | [![GitHub](https://img.shields.io/github/stars/DanaCohen95/Set-the-Scene?style=social)](https://github.com/DanaCohen95/Set-the-Scene) |
| 2023 | ICCV | UrbanGIRAFFE | [UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative Neural Feature Fields](https://arxiv.org/abs/2303.14167) | [Link](https://lv3d.github.io/urbanGIRAFFE/) | [![GitHub](https://img.shields.io/github/stars/freemty/urbanGIRAFFE?style=social)](https://github.com/freemty/urbanGIRAFFE) |
| 2023 | TPAMI | SceneDreamer | [SceneDreamer: Unbounded 3D Scene Generation From 2D Image Collections](https://arxiv.org/abs/2302.01330) | [Link](https://scene-dreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/FrozenBurning/SceneDreamer?style=social)](https://github.com/FrozenBurning/SceneDreamer) |
| 2023 | arXiv | CompoNeRF | [CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout](https://arxiv.org/abs/2303.13843) | [Link](https://vlislab22.github.io/componerf/) | [![GitHub](https://img.shields.io/github/stars/hbai98/Componerf?style=social)](https://github.com/hbai98/Componerf) |
| 2024 | 3DV | Comp3D | [Compositional 3D Scene Generation using Locally Conditioned Diffusion](https://arxiv.org/abs/2303.12218) | [Link](https://ryanpo.com/comp3d/) |  |
| 2024 | CVPR | CityDreamer | [CityDreamer: Compositional Generative Model of Unbounded 3D Cities](https://arxiv.org/abs/2309.00610) | [Link](https://www.infinitescript.com/project/city-dreamer/) | [![GitHub](https://img.shields.io/github/stars/hzxie/CityDreamer?style=social)](https://github.com/hzxie/CityDreamer) |
| 2024 | CVPR | BerfScene | [BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation](https://arxiv.org/abs/2312.02136) | [Link](https://zqh0253.github.io/BerfScene/) | [![GitHub](https://img.shields.io/github/stars/zqh0253/BerfScene?style=social)](https://github.com/zqh0253/BerfScene) |
| 2024 | NeurIPS | SceneCraft | [SceneCraft: Layout-Guided 3D Scene Generation](https://arxiv.org/abs/2410.09049) | [Link](https://orangesodahub.github.io/SceneCraft/) | [![GitHub](https://img.shields.io/github/stars/SceneCraft/?style=social)](https://github.com/OrangeSodahub/SceneCraft/) |
| 2024 | SIGGRAPH | BlockFusion | [BlockFusion: Expandable 3D Scene Generation Using Latent Tri-plane Extrapolation](https://arxiv.org/abs/2401.17053) | [Link](https://yang-l1.github.io/blockfusion/) | [![GitHub](https://img.shields.io/github/stars/Tencent/BlockFusion?style=social)](https://github.com/Tencent/BlockFusion) |
| 2024 | SIGGRAPH Asia | Frankenstein | [Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane](https://arxiv.org/abs/2403.16210) | [Link](https://wolfball.github.io/frankenstein/) | [![GitHub](https://img.shields.io/github/stars/Tencent/Frankenstein?style=social)](https://github.com/Tencent/Frankenstein) |
| 2024 | arXiv | Urban Architect | [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](https://arxiv.org/abs/2404.06780) | [Link](https://urbanarchitect.github.io) | [![GitHub](https://img.shields.io/github/stars/UrbanArchitect/UrbanArchitect?style=social)](https://github.com/UrbanArchitect/UrbanArchitect) |
| 2025 | CVPR | GaussianCity | [Generative Gaussian Splatting for Unbounded 3D City Generation](https://arxiv.org/abs/2406.06526) | [Link](https://haozhexie.com/project/gaussian-city) | [![GitHub](https://img.shields.io/github/stars/hzxie/GaussianCity?style=social)](https://github.com/hzxie/GaussianCity) |
| 2025 | ICLR | Layout-your-3D | [Layout-your-3D: Controllable and Precise 3D Generation with 2D Blueprint](https://arxiv.org/abs/2410.15391) | [Link](https://colezwhy.github.io/layoutyour3d/) | [![GitHub](https://img.shields.io/github/stars/Colezwhy/Layout-Your-3D?style=social)](https://github.com/Colezwhy/Layout-Your-3D) |
| 2025 | arXiv | Layout2Scene | [Layout2Scene: 3D Semantic Layout Guided Scene Generation viaÂ Geometry and Appearance Diffusion Priors](https://arxiv.org/abs/2501.02519) |  |  |
| 2025 | arXiv | CityDreamer4D | [CityDreamer4D: Compositional Generative Model of Unbounded 4D Cities](https://arxiv.org/abs/2501.08983) | [Link](https://haozhexie.com/project/city-dreamer-4d) | [![GitHub](https://img.shields.io/github/stars/hzxie/CityDreamer4D?style=social)](https://github.com/hzxie/CityDreamer4D) |

### Implicit Layout

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2021 | CVPR | GIRAFFE | [GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields](https://arxiv.org/abs/2011.12100) |  | [![GitHub](https://img.shields.io/github/stars/autonomousvision/giraffe?style=social)](https://github.com/autonomousvision/giraffe) |
| 2021 | ICCV | GSN | [Unconstrained Scene Generation With Locally Conditioned Radiance Fields](https://arxiv.org/abs/2104.00670) | [Link](https://apple.github.io/ml-gsn/) | [![GitHub](https://img.shields.io/github/stars/apple/ml-gsn?style=social)](https://github.com/apple/ml-gsn) |
| 2021 | ICCV |  | [Indoor Scene Generation From a Collection of Semantic-Segmented Depth Images](https://arxiv.org/abs/2108.09022) |  | [![GitHub](https://img.shields.io/github/stars/microsoft/SGSDI?style=social)](https://github.com/microsoft/SGSDI) |
| 2021 | ICML | NeRF-VAE | [NeRF-VAE: A geometry aware 3d scene generative model](https://arxiv.org/abs/2104.00587) |  |  |
| 2022 | NeurIPS | GAUDI | [GAUDI: A Neural Architect for Immersive 3D Scene Generation](https://arxiv.org/abs/2207.13751) |  | [![GitHub](https://img.shields.io/github/stars/apple/ml-gaudi?style=social)](https://github.com/apple/ml-gaudi) |
| 2023 | CVPR | Persistent Nature | [Persistent Nature: A generative model of unbounded 3D worlds](https://arxiv.org/abs/2303.13515) | [Link](https://chail.github.io/persistent-nature/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research?style=social)](https://github.com/google-research/google-research/tree/master/persistent-nature) |
| 2023 | CVPR | NeuralField-LDM | [NeuralField-LDM: Scene Generation with Hierarchical Latent Diffusion Models](https://arxiv.org/abs/2304.09787) | [Link](https://research.nvidia.com/labs/toronto-ai/NFLDM/) |  |
| 2023 | arXiv |  | [Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data](https://arxiv.org/abs/2301.00527) | [Link](https://github.com/zoomin-lee/scene-scale-diffusion) | [![GitHub](https://img.shields.io/github/stars/zoomin-lee/scene-scale-diffusion?style=social)](https://github.com/zoomin-lee/scene-scale-diffusion) |
| 2024 | CVPR | DiffInDScene | [DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation](https://arxiv.org/abs/2306.00519) | [Link](https://akirahero.github.io/diffindscene/) | [![GitHub](https://img.shields.io/github/stars/AkiraHero/diffindscene?style=social)](https://github.com/AkiraHero/diffindscene) |
| 2024 | CVPR | XCube | [XCube:Â Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies](https://arxiv.org/abs/2312.03806) | [Link](https://research.nvidia.com/labs/toronto-ai/xcube/) | [![GitHub](https://img.shields.io/github/stars/nv-tlabs/XCube?style=social)](https://github.com/nv-tlabs/XCube) |
| 2024 | CVPR | SemCity | [SemCity: Semantic Scene Generation with Triplane Diffusion](https://arxiv.org/abs/2403.07773) | [Link](https://sglab.kaist.ac.kr/SemCity/) | [![GitHub](https://img.shields.io/github/stars/zoomin-lee/SemCity?style=social)](https://github.com/zoomin-lee/SemCity) |
| 2024 | ECCV | PDD | [Pyramid Diffusion for Fine 3D Large Scene Generation](https://arxiv.org/abs/2311.12085) | [Link](https://yuheng.ink/project-page/pyramid-discrete-diffusion/) | [![GitHub](https://img.shields.io/github/stars/yuhengliu02/pyramid-discrete-diffusion?style=social)](https://github.com/yuhengliu02/pyramid-discrete-diffusion) |
| 2024 | NeurIPS | Director3D | [Director3D: Real-world Camera Trajectory and 3D Scene Generation from Text](https://arxiv.org/abs/2406.17601) | [Link](https://imlixinyang.github.io/director3d-page/) | [![GitHub](https://img.shields.io/github/stars/imlixinyang/director3d?style=social)](https://github.com/imlixinyang/director3d) |
| 2024 | arXiv | LT3SD | [LT3SD: Latent Trees for 3D Scene Diffusion](https://arxiv.org/abs/2409.08215) | [Link](https://quan-meng.github.io/projects/lt3sd/) | [![GitHub](https://img.shields.io/github/stars/quan-meng/lt3sd?style=social)](https://github.com/quan-meng/lt3sd) |
| 2025 | CVPR | Prometheus | [Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation](https://arxiv.org/abs/2412.21117) | [Link](https://freemty.github.io/project-prometheus/) | [![GitHub](https://img.shields.io/github/stars/XDimLab/Prometheus?style=social)](https://github.com/XDimLab/Prometheus) |
| 2025 | ICLR | DynamicCity | [DynamicCity: Large-Scale Occupancy Generation from Dynamic Scenes](https://arxiv.org/abs/2410.18084) | [Link](https://dynamic-city.github.io/) | [![GitHub](https://img.shields.io/github/stars/3DTopia/DynamicCity?style=social)](https://github.com/3DTopia/DynamicCity) |

## Image-based Generation

### Holistic Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2019 | ICIP |  | [360-Degree Image Completion by Two-Stage Conditional Gans](https://ieeexplore.ieee.org/abstract/document/8803435) |  |  |
| 2020 | CVPR | Sat2Ground | [Geometry-Aware Satellite-to-Ground Image Synthesis for Urban Areas](https://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_Geometry-Aware_Satellite-to-Ground_Image_Synthesis_for_Urban_Areas_CVPR_2020_paper.pdf) |  | [![GitHub](https://img.shields.io/github/stars/lizuoyue/sate_to_ground?style=social)](https://github.com/lizuoyue/sate_to_ground) |
| 2020 | WACV |  | [360 Panorama Synthesis from a Sparse Set of Images with Unknown Field of View](https://arxiv.org/abs/1904.03326) |  |  |
| 2021 | AAAI | SIG-SS | [Spherical Image Generation from a Single Image by Considering Scene Symmetry](https://aaai.org/papers/01513-spherical-image-generation-from-a-single-image-by-considering-scene-symmetry/) |  | [![GitHub](https://img.shields.io/github/stars/hara012/sig-ss?style=social)](https://github.com/hara012/sig-ss) |
| 2021 | CVPR | EnvMapNet | [HDR Environment Map Estimation for Real-Time Augmented Reality](https://arxiv.org/abs/2011.10687) | [Link](https://machinelearning.apple.com/research/hdr-environment-map-estimation) | [![GitHub](https://img.shields.io/github/stars/apple/ml-envmapnet?style=social)](https://github.com/apple/ml-envmapnet) |
| 2021 | ICCV | Sat2vid | [Sat2vid: Street-view panoramic video synthesis from a single satellite image](https://arxiv.org/abs/2012.06628) |  |  |
| 2022 | 3DV | ImmerseGAN | [Guided Co-Modulated GAN for 360Â° Field of View Extrapolation](https://arxiv.org/abs/2204.07286) | [Link](https://lvsn.github.io/ImmerseGAN/) |  |
| 2022 | CVPR | OmniDreamer | [Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://arxiv.org/abs/2203.14668) | [Link](https://akmtn.github.io/omni-dreamer/) | [![GitHub](https://img.shields.io/github/stars/akmtn/OmniDreamer?style=social)](https://github.com/akmtn/OmniDreamer) |
| 2022 | ECCV | BIPS | [BIPS: Bi-modal Indoor Panorama Synthesis via Residual Depth-aided Adversarial Learning](https://arxiv.org/abs/2112.06179) |  | [![GitHub](https://img.shields.io/github/stars/chang9711/BIPS?style=social)](https://github.com/chang9711/BIPS) |
| 2022 | SIGGRAPH Asia | Text2Light | [Text2Light: Zero-Shot Text-Driven HDR Panorama Generation](https://arxiv.org/abs/2209.09898) | [Link](https://frozenburning.github.io/projects/text2light/) | [![GitHub](https://img.shields.io/github/stars/FrozenBurning/Text2Light?style=social)](https://github.com/FrozenBurning/Text2Light) |
| 2022 | TMM | PanoGAN | [Cross-View Panorama Image Synthesis](https://arxiv.org/abs/2203.11832) |  | [![GitHub](https://img.shields.io/github/stars/sswuai/PanoGAN?style=social)](https://github.com/sswuai/PanoGAN) |
| 2022 | TPAMI | Sat2Str | [Geometry-Guided Street-View Panorama Synthesis from Satellite Imagery](https://arxiv.org/abs/2103.01623) |  | [![GitHub](https://img.shields.io/github/stars/YujiaoShi/Sat2StrPanoramaSynthesis?style=social)](https://github.com/YujiaoShi/Sat2StrPanoramaSynthesis) |
| 2023 | CVPR | DiffCollage | [DiffCollage: Parallel Generation of Large Content with Diffusion Models](https://arxiv.org/abs/2303.17076) | [Link](https://research.nvidia.com/labs/dir/diffcollage/) |  |
| 2023 | ICCV | Sat2Density | [Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs](https://arxiv.org/abs/2303.14672) | [Link](https://sat2density.github.io/) | [![GitHub](https://img.shields.io/github/stars/qianmingduowan/Sat2Density?style=social)](https://github.com/qianmingduowan/Sat2Density) |
| 2023 | MM | PanoDiff | [360-Degree Panorama Generation from Few Unregistered NFoV Images](https://arxiv.org/abs/2308.14686) |  | [![GitHub](https://img.shields.io/github/stars/shanemankiw/Panodiff?style=social)](https://github.com/shanemankiw/Panodiff) |
| 2023 | NeurIPS | MVDiffusion | [MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion](https://arxiv.org/abs/2307.01097) | [Link](https://mvdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/Tangshitao/MVDiffusion?style=social)](https://github.com/Tangshitao/MVDiffusion) |
| 2023 | TPAMI |  | [Spherical Image Generation From a Few Normal-Field-of-View Images by Considering Scene Symmetry](https://ieeexplore.ieee.org/document/9925617) |  |  |
| 2023 | arXiv | LDM3D | [LDM3D: Latent Diffusion Model for 3D](https://arxiv.org/abs/2305.10853) |  |  |
| 2023 | arXiv | Diffusion360 | [Diffusion360: Seamless 360 Degree Panoramic Image Generation based on Diffusion Models](https://arxiv.org/abs/2311.13141) |  | [![GitHub](https://img.shields.io/github/stars/ArcherFMY/SD-T2I-360PanoImage?style=social)](https://github.com/ArcherFMY/SD-T2I-360PanoImage) |
| 2024 | ICLR | PanoDiffusion | [PanoDiffusion: 360-degree Panorama Outpainting via Diffusion](https://arxiv.org/abs/2307.03177) | [Link](https://sm0kywu.github.io/panodiffusion/) | [![GitHub](https://img.shields.io/github/stars/PanoDiffusion/PanoDiffusion?style=social)](https://github.com/PanoDiffusion/PanoDiffusion) |
| 2024 | CVPR | ControlRoom3D | [ControlRoom3D ðŸ¤–Room Generation using Semantic Proxy Rooms](https://arxiv.org/abs/2312.05208) | [Link](https://jonasschult.github.io/ControlRoom3D/) |  |
| 2024 | CVPR | Sat2Scene | [Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion](https://arxiv.org/abs/2401.10786) |  | [![GitHub](https://img.shields.io/github/stars/lizuoyue/sat2scene?style=social)](https://github.com/lizuoyue/sat2scene) |
| 2024 | CVPR | PanFusion | [Taming stable diffusion for text to 360â—¦ panorama image generation](https://arxiv.org/abs/2404.07949) | [Link](https://chengzhag.github.io/publication/panfusion/) | [![GitHub](https://img.shields.io/github/stars/chengzhag/PanFusion?style=social)](https://github.com/chengzhag/PanFusion) |
| 2024 | ECCV | DreamScene360 | [DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting](https://arxiv.org/abs/2404.06903) | [Link](https://dreamscene360.github.io/) | [![GitHub](https://img.shields.io/github/stars/ShijieZhou-UCLA/DreamScene360?style=social)](https://github.com/ShijieZhou-UCLA/DreamScene360) |
| 2024 | ECCV |  | [Geospecific View Generation - Geometry-Context Aware High-resolution Ground View Inference from Satellite Views](https://arxiv.org/abs/2407.08061) | [Link](https://gdaosu.github.io/geocontext/) |  |
| 2024 | IJCAI | FastScene | [FastScene: Text-Driven Fast Indoor 3D Scene Generation via Panoramic Gaussian Splatting](https://arxiv.org/abs/2405.05768) |  | [![GitHub](https://img.shields.io/github/stars/Mr-Ma-yikun/FastScene?style=social)](https://github.com/Mr-Ma-yikun/FastScene) |
| 2024 | NeurIPS | DiffPano | [DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion](https://arxiv.org/abs/2410.24203) | [Link](https://zju3dv.github.io/DiffPano/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/DiffPano?style=social)](https://github.com/zju3dv/DiffPano) |
| 2024 | TPAMI | PERF | [PERF: Panoramic Neural Radiance Field from a Single Panorama](https://arxiv.org/abs/2310.16831) | [Link](https://perf-project.github.io/) | [![GitHub](https://img.shields.io/github/stars/perf-project/PeRF?style=social)](https://github.com/perf-project/PeRF) |
| 2024 | TVCG | Dream360 | [Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via Transformer-Based 360Â° Image Outpainting](https://arxiv.org/abs/2401.10564) |  |  |
| 2024 | WACV | StitchDiffusion | [Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models](https://arxiv.org/abs/2310.18840) | [Link](https://littlewhitesea.github.io/stitchdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/littlewhitesea/StitchDiffusion?style=social)](https://github.com/littlewhitesea/StitchDiffusion) |
| 2024 | arXiv | HoloDreamer | [HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions](https://arxiv.org/abs/2407.15187) | [Link](https://zhouhyocean.github.io/holodreamer/) | [![GitHub](https://img.shields.io/github/stars/zhouhyOcean/HoloDreamer?style=social)](https://github.com/zhouhyOcean/HoloDreamer) |
| 2024 | arXiv | SceneDreamer360 | [SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with PanoramicÂ Gaussian Splatting](https://arxiv.org/abs/2408.13711) | [Link](https://scenedreamer360.github.io/) | [![GitHub](https://img.shields.io/github/stars/liwrui/SceneDreamer360?style=social)](https://github.com/liwrui/SceneDreamer360) |
| 2025 | ICLR | CubeDiff | [CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation](https://arxiv.org/abs/2501.17162) | [Link](https://cubediff.github.io/) |  |
| 2025 | SIGGRAPH | LayerPano3D | [LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation](https://arxiv.org/abs/2408.13252) | [Link](https://ys-imtech.github.io/projects/LayerPano3D/) | [![GitHub](https://img.shields.io/github/stars/3DTopia/LayerPano3D?style=social)](https://github.com/3DTopia/LayerPano3D) |

### Iterative Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2019 | TOG |  | [3D Ken Burns Effect from a Single Image](https://arxiv.org/abs/1909.05483) | [Link](https://sniklaus.com/kenburns) | [![GitHub](https://img.shields.io/github/stars/sniklaus/3d-ken-burns?style=social)](https://github.com/sniklaus/3d-ken-burns) |
| 2020 | CVPR | SynSin | [SynSin: End-to-end view synthesis from a single image](https://arxiv.org/abs/1912.08804) | [Link](https://www.robots.ox.ac.uk/~ow/synsin.html) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/synsin?style=social)](https://github.com/facebookresearch/synsin) |
| 2020 | CVPR | 3D Photo | [3D Photography Using Context-Aware Layered Depth Inpainting](https://arxiv.org/abs/2004.04727) | [Link](https://shihmengli.github.io/3D-Photo-Inpainting/) | [![GitHub](https://img.shields.io/github/stars/vt-vl-lab/3d-photo-inpainting?style=social)](https://github.com/vt-vl-lab/3d-photo-inpainting) |
| 2020 | CVPR |  | [Single-View View Synthesis with Multiplane Images](https://arxiv.org/abs/2004.11364) | [Link](https://single-view-mpi.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research?style=social)](https://github.com/google-research/google-research/tree/master/single_view_mpi) |
| 2020 | NeurIPS | GVS | [Generative View Synthesis: From Single-view Semantics to Novel-view Images](https://arxiv.org/abs/2008.09106) | [Link](https://gvsnet.github.io/) | [![GitHub](https://img.shields.io/github/stars/tedyhabtegebrial/gvsnet?style=social)](https://github.com/tedyhabtegebrial/gvsnet) |
| 2021 | ICCV | Worldsheet | [Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image](https://arxiv.org/abs/2012.09854) | [Link](https://worldsheet.github.io/) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/worldsheet?style=social)](https://github.com/facebookresearch/worldsheet) |
| 2021 | ICCV | InfiniteNature | [Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image](https://arxiv.org/abs/2012.09855) | [Link](https://infinite-nature.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research?style=social)](https://github.com/google-research/google-research/tree/master/infinite_nature) |
| 2021 | ICCV | GFVS | [Geometry-free view synthesis: Transformers and no 3d priors](https://arxiv.org/abs/2104.07652) | [Link](https://compvis.github.io/geometry-free-view-synthesis/) | [![GitHub](https://img.shields.io/github/stars/CompVis/geometry-free-view-synthesis?style=social)](https://github.com/CompVis/geometry-free-view-synthesis) |
| 2021 | ICCV | Pathdreamer | [Pathdreamer: A World Model for Indoor Navigation](https://arxiv.org/abs/2105.08756) | [Link](https://google-research.github.io/pathdreamer/) | [![GitHub](https://img.shields.io/github/stars/google-research/pathdreamer?style=social)](https://github.com/google-research/pathdreamer) |
| 2021 | ICCV | PixelSynth | [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892) | [Link](https://crockwell.github.io/pixelsynth/) | [![GitHub](https://img.shields.io/github/stars/crockwell/pixelsynth?style=social)](https://github.com/crockwell/pixelsynth) |
| 2022 | CVPR | LOTR | [Look outside the room: Synthesizing a consistent long-term 3d scene video from a single image](https://arxiv.org/abs/2203.09457) | [Link](https://xrenaa.github.io/look-outside-room/) | [![GitHub](https://img.shields.io/github/stars/xrenaa/Look-Outside-Room?style=social)](https://github.com/xrenaa/Look-Outside-Room) |
| 2022 | ECCV | InfiniteNature-Zero | [InfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images](https://arxiv.org/abs/2207.11148) | [Link](https://infinite-nature-zero.github.io/) | [![GitHub](https://img.shields.io/github/stars/google-research/google-research?style=social)](https://github.com/google-research/google-research/tree/master/infinite_nature_zero) |
| 2022 | NeurIPS | SGAM | [SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping](https://openreview.net/pdf?id=17KCLTbRymw) | [Link](https://yshen47.github.io/sgam/) | [![GitHub](https://img.shields.io/github/stars/yshen47/SGAM_NeurIPS22?style=social)](https://github.com/yshen47/SGAM_NeurIPS22) |
| 2023 | AAAI | SE3DS | [Simple and Effective Synthesis of Indoor 3D Scenes](https://arxiv.org/abs/2204.02960) |  | [![GitHub](https://img.shields.io/github/stars/google-research/se3ds?style=social)](https://github.com/google-research/se3ds) |
| 2023 | CVPR |  | [Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single Semantic Mask](https://arxiv.org/abs/2302.07224) | [Link](https://zju3dv.github.io/paintingnature/) | [![GitHub](https://img.shields.io/github/stars/zhanghe3z/PaintingNature?style=social)](https://github.com/zhanghe3z/PaintingNature) |
| 2023 | CVPR | 3D Cinemagraphy | [3D Cinemagraphy from a Single Image](https://arxiv.org/abs/2303.05724) | [Link](https://xingyi-li.github.io/3d-cinemagraphy/) | [![GitHub](https://img.shields.io/github/stars/xingyi-li/3d-cinemagraphy?style=social)](https://github.com/xingyi-li/3d-cinemagraphy) |
| 2023 | CVPR |  | [Consistent View Synthesis with Pose-Guided Diffusion Models](https://arxiv.org/abs/2303.17598) | [Link](https://poseguided-diffusion.github.io/) |  |
| 2023 | ICCV | DiffDreamer | [DiffDreamer: Towards Consistent Unsupervised Single-view Scene Extrapolation with Conditional Diffusion Models](https://arxiv.org/abs/2211.12131) | [Link](https://primecai.github.io/diffdreamer) | [![GitHub](https://img.shields.io/github/stars/primecai/DiffDreamer?style=social)](https://github.com/primecai/DiffDreamer) |
| 2023 | ICCV | Text2Room | [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/abs/2303.11989) | [Link](https://lukashoel.github.io/text-to-room/) | [![GitHub](https://img.shields.io/github/stars/lukasHoel/text2room?style=social)](https://github.com/lukasHoel/text2room) |
| 2023 | ICCV |  | [Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models](https://arxiv.org/abs/2304.10700) | [Link](https://yorkucvil.github.io/Photoconsistent-NVS/) | [![GitHub](https://img.shields.io/github/stars/YorkUCVIL/Photoconsistent-NVS?style=social)](https://github.com/YorkUCVIL/Photoconsistent-NVS) |
| 2023 | MM | Make-It-4D | [Make-It-4D: Synthesizing a Consistent Long-Term Dynamic Scene Video from a Single Image](https://arxiv.org/abs/2308.10257) |  | [![GitHub](https://img.shields.io/github/stars/leoShen917/Make-It-4D?style=social)](https://github.com/leoShen917/Make-It-4D) |
| 2023 | NeurIPS | SceneScape | [SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/abs/2302.01133) | [Link](https://scenescape.github.io/) | [![GitHub](https://img.shields.io/github/stars/RafailFridman/SceneScape?style=social)](https://github.com/RafailFridman/SceneScape) |
| 2023 | NeurIPS | PanoGen | [PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation](https://arxiv.org/abs/2305.19195) | [Link](https://pano-gen.github.io/) | [![GitHub](https://img.shields.io/github/stars/jialuli-luka/PanoGen?style=social)](https://github.com/jialuli-luka/PanoGen) |
| 2023 | arXiv | LucidDreamer | [LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes](https://arxiv.org/abs/2311.13384) | [Link](https://luciddreamer-cvlab.github.io/) | [![GitHub](https://img.shields.io/github/stars/luciddreamer-cvlab/LucidDreamer?style=social)](https://github.com/luciddreamer-cvlab/LucidDreamer) |
| 2023 | arXiv | Text2Immersion | [Text2Immersion: Generative Immersive Scene with 3D Gaussians](https://arxiv.org/abs/2312.09242) | [Link](https://ken-ouyang.github.io/text2immersion/index.html) |  |
| 2024 | AAAI | AOG-Net | [Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation](https://arxiv.org/abs/2309.03467) |  | [![GitHub](https://img.shields.io/github/stars/zhuqiangLu/AOG-NET-360?style=social)](https://github.com/zhuqiangLu/AOG-NET-360) |
| 2024 | CVPR | WonderJourney | [WonderJourney: Going from Anywhere to Everywhere](https://arxiv.org/abs/2312.03884) | [Link](https://kovenyu.com/wonderjourney/) | [![GitHub](https://img.shields.io/github/stars/KovenYu/WonderJourney?style=social)](https://github.com/KovenYu/WonderJourney) |
| 2024 | CVPR | 3D-SceneDreamer | [3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation](https://arxiv.org/abs/2403.09439) | [Link](https://microtreei.github.io/) |  |
| 2024 | ECCV | PanoFree | [PanoFree: Tuning-Free Holistic Multi-view Image Generation with Cross-view Self-Guidance](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03887.pdf) | [Link](https://panofree.github.io/) | [![GitHub](https://img.shields.io/github/stars/zxcvfd13502/PanoFree?style=social)](https://github.com/zxcvfd13502/PanoFree) |
| 2024 | MM | iControl3D | [iControl3D: An Interactive System for Controllable 3D Scene Generation](https://arxiv.org/abs/2408.01678) |  | [![GitHub](https://img.shields.io/github/stars/xingyi-li/iControl3D?style=social)](https://github.com/xingyi-li/iControl3D) |
| 2024 | NeurIPS | ODIN | [From an Image to a Scene: Learning to Imagine the World from a Million 360Â° Videos](https://arxiv.org/abs/2412.07770) | [Link](https://mattwallingford.github.io/ODIN/) | [![GitHub](https://img.shields.io/github/stars/MattWallingford/360-1M?style=social)](https://github.com/MattWallingford/360-1M) |
| 2024 | TVCG | Text2NeRF | [Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields](https://arxiv.org/abs/2305.11588) | [Link](https://eckertzhang.github.io/Text2NeRF.github.io/) | [![GitHub](https://img.shields.io/github/stars/eckertzhang/Text2NeRF?style=social)](https://github.com/eckertzhang/Text2NeRF) |
| 2024 | arXiv | ART3D | [ART3D: 3D Gaussian Splatting for Text-Guided Artistic Scenes Generation](https://arxiv.org/abs/2405.10508) |  |  |
| 2024 | arXiv | OPa-Ma | [OPa-Ma: Text Guided Mamba for 360-degree Image Out-painting](https://arxiv.org/abs/2407.10923) |  | [![GitHub](https://img.shields.io/github/stars/PengleiGao/OPaMa?style=social)](https://github.com/PengleiGao/OPaMa) |
| 2024 | arXiv | Scene123 | [Scene123: One Prompt to 3D Scene Generation via Video-Assisted and Consistency-Enhanced MAE](https://arxiv.org/abs/2408.05477) | [Link](https://yiyingyang12.github.io/Scene123.github.io/) | [![GitHub](https://img.shields.io/github/stars/YiyingYang12/Scene123?style=social)](https://github.com/YiyingYang12/Scene123) |
| 2025 | 3DV | RealmDreamer | [RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion](https://arxiv.org/abs/2404.07199) | [Link](https://realmdreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/jaidevshriram/realmdreamer?style=social)](https://github.com/jaidevshriram/realmdreamer) |
| 2025 | CVPR | WonderWorld | [WonderWorld: Interactive 3D Scene Generation from a Single Image](https://arxiv.org/abs/2406.09394) | [Link](https://kovenyu.com/wonderworld/) | [![GitHub](https://img.shields.io/github/stars/KovenYu/WonderWorld?style=social)](https://github.com/KovenYu/WonderWorld) |
| 2025 | ICLR | 3D-MOM | [Optimizing 4D Gaussians for Dynamic Scene Video from Single Landscape Images](https://openreview.net/forum?id=IcYDRzcccP) | [Link](https://paper.pnu-cvsp.com/ICLR2025_3D-MOM/) | [![GitHub](https://img.shields.io/github/stars/InHwanJin/3DMOM?style=social)](https://github.com/InHwanJin/3DMOM) |
| 2025 | arXiv | WonderTurbo | [WonderTurbo: Generating Interactive 3D World in 0.72 Seconds](https://arxiv.org/abs/2504.02261) | [Link](https://wonderturbo.github.io/) | [![GitHub](https://img.shields.io/github/stars/GigaAI-research/WonderTurbo?style=social)](https://github.com/GigaAI-research/WonderTurbo) |


## Video-based Generation

### Two-stage Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2024 | SIGGRAPH | Streetscapes | [Streetscapes Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion](https://arxiv.org/abs/2407.13759) | [Link](https://boyangdeng.com/streetscapes/) |  |
| 2024 | NeurIPS | 4Real | [4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models](https://arxiv.org/abs/2406.07472) | [Link](https://snap-research.github.io/4Real/) | [![GitHub](https://img.shields.io/github/stars/snap-research/4Real?style=social)](https://github.com/snap-research/4Real) |
| 2024 | arXiv | VividDream | [VividDream: Generating 3D Scene with Ambient Dynamics](https://arxiv.org/abs/2405.20334) |  |  |
| 2024 | arXiv | DimensionX | [DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion](https://arxiv.org/abs/2411.04928) | [Link](https://chenshuo20.github.io/DimensionX/) | [![GitHub](https://img.shields.io/github/stars/wenqsun/DimensionX?style=social)](https://github.com/wenqsun/DimensionX) |
| 2024 | arXiv | PaintScene4D | [PaintScene4D: Consistent 4D Scene Generation from Text Prompts](https://arxiv.org/abs/2412.04471) | [Link](https://paintscene4d.github.io/) | [![GitHub](https://img.shields.io/github/stars/paintscene4d/paintscene4d.github.io?style=social)](https://github.com/paintscene4d/paintscene4d.github.io) |
| 2025 | ICLR | GenXD | [GenXD: Generating Any 3D and 4D Scenes](https://arxiv.org/abs/2411.02319) | [Link](https://gen-x-d.github.io/) | [![GitHub](https://img.shields.io/github/stars/HeliosZhao/GenXD?style=social)](https://github.com/HeliosZhao/GenXD) |
| 2025 | CVPR | StarGen | [StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation](https://arxiv.org/abs/2501.05763) | [Link](https://zju3dv.github.io/StarGen/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/StarGen?style=social)](https://github.com/zju3dv/StarGen) |
| 2025 | arXiv | Free4D | [Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency](https://arxiv.org/abs/2503.20785) | [Link](https://free4d.github.io/) | [![GitHub](https://img.shields.io/github/stars/TQTQliu/Free4D?style=social)](https://github.com/TQTQliu/Free4D) |

### One-stage Generation

| Year | Venue | Acronym | Paper | Project | Code |
|------|-------|---------|-------|---------|------|
| 2023 | arXiv | GAIA-1 | [GAIA-1: A Generative World Model for Autonomous Driving](https://arxiv.org/abs/2309.17080) |  |  |
| 2024 | ICLR | MagicDrive | [MagicDrive: Street View Generation with Diverse 3D Geometry Control](https://arxiv.org/abs/2310.02601) | [Link](https://gaoruiyuan.com/magicdrive/) | [![GitHub](https://img.shields.io/github/stars/cure-lab/MagicDrive?style=social)](https://github.com/cure-lab/MagicDrive) |
| 2024 | CVPR | Panacea | [Panacea: Panoramic and Controllable Video Generation for Autonomous Driving](https://arxiv.org/abs/2311.16813) | [Link](https://panacea-ad.github.io/) | [![GitHub](https://img.shields.io/github/stars/wenyuqing/panacea?style=social)](https://github.com/wenyuqing/panacea) |
| 2024 | CVPR | Drive-WM | [Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving](https://arxiv.org/abs/2311.17918) | [Link](https://drive-wm.github.io/) | [![GitHub](https://img.shields.io/github/stars/BraveGroup/Drive-WM?style=social)](https://github.com/BraveGroup/Drive-WM) |
| 2024 | CVPR | 360DVD | [360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model](https://arxiv.org/abs/2401.06578) | [Link](https://akaneqwq.github.io/360DVD/) | [![GitHub](https://img.shields.io/github/stars/Akaneqwq/360DVD?style=social)](https://github.com/Akaneqwq/360DVD) |
| 2024 | ECCV | DriveDreamer | [DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving](https://arxiv.org/abs/2309.09777) | [Link](https://drivedreamer.github.io/) | [![GitHub](https://img.shields.io/github/stars/JeffWang987/DriveDreamer?style=social)](https://github.com/JeffWang987/DriveDreamer) |
| 2024 | ECCV | DrivingDiffusion | [DrivingDiffusion: Layout-Guided Multi-View Driving Scenarios Video Generation with Latent Diffusion Model](https://arxiv.org/abs/2310.07771) | [Link](https://drivingdiffusion.github.io/) | [![GitHub](https://img.shields.io/github/stars/shalfun/DrivingDiffusion?style=social)](https://github.com/shalfun/DrivingDiffusion) |
| 2024 | ECCV | WoVoGen | [WoVoGen: World Volume-Aware Diffusion forÂ Controllable Multi-camera Driving Scene Generation](https://arxiv.org/abs/2312.02934) |  | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/WoVoGen?style=social)](https://github.com/fudan-zvg/WoVoGen) |
| 2024 | NeurIPS | Vista | [Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability](https://arxiv.org/abs/2405.17398) | [Link](https://opendrivelab.com/Vista/) | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/Vista?style=social)](https://github.com/OpenDriveLab/Vista) |
| 2024 | arXiv | DriveDreamer-2 | [DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation](https://arxiv.org/abs/2403.06845) | [Link](https://drivedreamer2.github.io/) | [![GitHub](https://img.shields.io/github/stars/f1yfisher/DriveDreamer2?style=social)](https://github.com/f1yfisher/DriveDreamer2) |
| 2024 | arXiv | DIAMOND | [Diffusion for World Modeling: Visual Details Matter in Atari](https://arxiv.org/abs/2405.12399) | [Link](https://diamond-wm.github.io/) | [![GitHub](https://img.shields.io/github/stars/eloialonso/diamond?style=social)](https://github.com/eloialonso/diamond) |
| 2024 | arXiv | MagicDrive3D | [MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes](https://arxiv.org/abs/2405.14475) | [Link](https://gaoruiyuan.com/magicdrive3d/) | [![GitHub](https://img.shields.io/github/stars/flymin/MagicDrive3D?style=social)](https://github.com/flymin/MagicDrive3D) |
| 2024 | arXiv | Delphi | [Unleashing Generalization of End-to-End Autonomous Driving with Controllable Long Video Generation](https://arxiv.org/abs/2406.01349) | [Link](https://westlake-autolab.github.io/delphi.github.io/) | [![GitHub](https://img.shields.io/github/stars/westlake-autolab/Delphi?style=social)](https://github.com/westlake-autolab/Delphi) |
| 2024 | arXiv | BEVWorld | [BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space](https://arxiv.org/abs/2407.05679) |  | [![GitHub](https://img.shields.io/github/stars/zympsyche/BevWorld?style=social)](https://github.com/zympsyche/BevWorld) |
| 2024 | arXiv | DriveArena | [DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving](https://arxiv.org/abs/2408.00415) | [Link](https://pjlab-adg.github.io/DriveArena/) | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/DriveArena?style=social)](https://github.com/PJLab-ADG/DriveArena) |
| 2024 | arXiv | GameNGen | [Diffusion Models Are Real-Time Game Engines](https://arxiv.org/abs/2408.14837) | [Link](https://gamengen.github.io/) |  |
| 2024 | arXiv | DiVE | [DiVE: DiT-based Video Generation with Enhanced Control](https://arxiv.org/abs/2409.01595) | [Link](https://liautoad.github.io/DIVE/) | [![GitHub](https://img.shields.io/github/stars/LiAutoAD/DIVE?style=social)](https://github.com/LiAutoAD/DIVE) |
| 2024 | arXiv | DreamForge | [DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes](https://arxiv.org/abs/2409.04003v3) | [Link](https://pjlab-adg.github.io/DriveArena/dreamforge/) |  |
| 2024 | arXiv | DriveScape | [DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation](https://arxiv.org/abs/2409.05463) | [Link](https://metadrivescape.github.io/papers_project/drivescapev1/index.html) |  |
| 2024 | arXiv | SyntheOcc | [SyntheOcc: Synthesize Geometric-Controlled Street View Images through 3D Semantic MPIs](https://arxiv.org/abs/2410.00337v1) | [Link](https://len-li.github.io/syntheocc-web/) | [![GitHub](https://img.shields.io/github/stars/EnVision-Research/SyntheOcc?style=social)](https://github.com/EnVision-Research/SyntheOcc) |
| 2024 | arXiv | MagicDrive-V2 | [MagicDrive-V2: High-Resolution Long Video Generation for Autonomous Driving with Adaptive Control](https://arxiv.org/abs/2411.13807v3) | [Link](https://gaoruiyuan.com/magicdrivedit/) | [![GitHub](https://img.shields.io/github/stars/flymin/MagicDriveDiT?style=social)](https://github.com/flymin/MagicDriveDiT) |
| 2024 | arXiv | HoloDrive | [HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving](https://arxiv.org/abs/2412.01407) |  |  |
| 2024 | arXiv | CogDriving | [Seeing Beyond Views: Multi-View Driving Scene Video Generation with Holistic Attention](https://arxiv.org/abs/2412.03520) | [Link](https://luhannan.github.io/CogDrivingPage/) |  |
| 2024 | arXiv | Imagine360 | [Imagine360: Immersive 360 Video Generation from Perspective Anchor](https://arxiv.org/abs/2412.03552) | [Link](https://ys-imtech.github.io/projects/Imagine360/) | [![GitHub](https://img.shields.io/github/stars/YS-IMTech/Imagine360?style=social)](https://github.com/YS-IMTech/Imagine360) |
| 2024 | arXiv | InfiniCube | [InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models](https://arxiv.org/abs/2412.03934) | [Link](https://research.nvidia.com/labs/toronto-ai/infinicube/) |  |
| 2024 | arXiv | StreetCrafter | [StreetCrafter: Street View Synthesiswith Controllable Video Diffusion Models](https://arxiv.org/abs/2412.13188) | [Link](https://zju3dv.github.io/street_crafter/) | [![GitHub](https://img.shields.io/github/stars/zju3dv/street_crafter?style=social)](https://github.com/zju3dv/street_crafter) |
| 2024 | arXiv | DrivingWorld | [DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT](https://arxiv.org/abs/2412.19505) | [Link](https://huxiaotaostasy.github.io/DrivingWorld/) | [![GitHub](https://img.shields.io/github/stars/YvanYin/DrivingWorld?style=social)](https://github.com/YvanYin/DrivingWorld) |
| 2025 | ICLR | 4K4DGen | [4K4DGen: Panoramic 4D Generation at 4K Resolution](https://arxiv.org/abs/2406.13527) | [Link](https://4k4dgen.github.io/) |  |
| 2025 | ICLR | GameGen-X | [GameGen-X: Interactive Open-world Game Video Generation](https://arxiv.org/abs/2411.00769v3) | [Link](https://gamegen-x.github.io/) | [![GitHub](https://img.shields.io/github/stars/GameGen-X/GameGen-X?style=social)](https://github.com/GameGen-X/GameGen-X) |
| 2025 | ICLR | Genex | [Generative World Explorer](https://arxiv.org/abs/2411.11844) | [Link](https://generative-world-explorer.github.io/) | [![GitHub](https://img.shields.io/github/stars/Beckschen/genEx?style=social)](https://github.com/Beckschen/genEx) |
| 2025 | ICLR | GLAD | [Glad: A Streaming Scene Generator for Autonomous Driving](https://arxiv.org/abs/2503.00045) |  |  |
| 2025 | CVPR | DrivingSphere | [DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation](https://arxiv.org/abs/2411.11252) | [Link](https://yanty123.github.io/DrivingSphere/) | [![GitHub](https://img.shields.io/github/stars/yanty123/DrivingSphere?style=social)](https://github.com/yanty123/DrivingSphere) |
| 2025 | CVPR | UniScene | [UniScene: Unified Occupancy-centric Driving Scene Generation](https://arxiv.org/abs/2412.05435) | [Link](https://arlo0o.github.io/uniscene/) | [![GitHub](https://img.shields.io/github/stars/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation?style=social)](https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation) |
| 2025 | CVPR | GEM | [GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control](https://arxiv.org/abs/2412.11198) | [Link](https://vita-epfl.github.io/GEM.github.io/) | [![GitHub](https://img.shields.io/github/stars/vita-epfl/GEM?style=social)](https://github.com/vita-epfl/GEM) |
| 2025 | CVPR | UMGen | [Generating Multimodal Driving Scenes via Next-Scene Prediction](https://arxiv.org/abs/2503.14945) | [Link](https://yanhaowu.github.io/UMGen/) | [![GitHub](https://img.shields.io/github/stars/YanhaoWu/UMGen/?style=social)](https://github.com/YanhaoWu/UMGen/) |
| 2025 | arXiv | DreamDrive | [DreamDrive: Generative 4D Scene Modeling from Street View Images](https://arxiv.org/abs/2501.00601) | [Link](https://pointscoder.github.io/DreamDrive/) |  |
| 2025 | arXiv | MaskGWM | [MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction](https://arxiv.org/abs/2502.11663) | [Link](https://sensetime-fvg.github.io/MaskGWM/) | [![GitHub](https://img.shields.io/github/stars/SenseTime-FVG/OpenDWM?style=social)](https://github.com/SenseTime-FVG/OpenDWM) |
| 2025 | arXiv | UniFuture | [Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception](https://arxiv.org/abs/2503.13587) | [Link](https://dk-liang.github.io/UniFuture/) | [![GitHub](https://img.shields.io/github/stars/dk-liang/UniFuture?style=social)](https://github.com/dk-liang/UniFuture) |
| 2025 | arXiv | DiST-4D | [DiST-4D: Disentangled Spatiotemporal Diffusion with Metric Depth for 4D Driving Scene Generation](https://arxiv.org/abs/2503.15208) | [Link](https://royalmelon0505.github.io/DiST-4D/) | [![GitHub](https://img.shields.io/github/stars/royalmelon0505/dist4d?style=social)](https://github.com/royalmelon0505/dist4d) |
| 2025 | arXiv | GAIA-2 | [GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving](https://arxiv.org/abs/2503.20523) | [Link](https://wayve.ai/thinking/gaia-2/) |  |

